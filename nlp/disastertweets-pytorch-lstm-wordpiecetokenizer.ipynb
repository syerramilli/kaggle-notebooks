{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45686ce6",
   "metadata": {
    "papermill": {
     "duration": 0.007698,
     "end_time": "2024-06-05T13:31:36.206209",
     "exception": false,
     "start_time": "2024-06-05T13:31:36.198511",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Introduction\n",
    "\n",
    "In this notebook, we will train a LSTM based classification model to predict whether the event described in a tweet is a real disaster or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd2b305d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-06-05T13:31:36.222030Z",
     "iopub.status.busy": "2024-06-05T13:31:36.221730Z",
     "iopub.status.idle": "2024-06-05T13:31:43.861867Z",
     "shell.execute_reply": "2024-06-05T13:31:43.861108Z"
    },
    "papermill": {
     "duration": 7.650584,
     "end_time": "2024-06-05T13:31:43.864168",
     "exception": false,
     "start_time": "2024-06-05T13:31:36.213584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import fasttext\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from tokenizers import decoders, models, normalizers, pre_tokenizers, processors, trainers, Tokenizer\n",
    "from transformers import BertTokenizerFast\n",
    "\n",
    "from pathlib import Path\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16e80117",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T13:31:43.880803Z",
     "iopub.status.busy": "2024-06-05T13:31:43.879992Z",
     "iopub.status.idle": "2024-06-05T13:31:43.884766Z",
     "shell.execute_reply": "2024-06-05T13:31:43.884008Z"
    },
    "papermill": {
     "duration": 0.014973,
     "end_time": "2024-06-05T13:31:43.886706",
     "exception": false,
     "start_time": "2024-06-05T13:31:43.871733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## CONFIG\n",
    "MAX_VOCAB_SIZE = 5000\n",
    "MIN_FREQUENCY = 10\n",
    "MAX_SEQ_LEN = 50\n",
    "BATCH_SIZE = 128\n",
    "MAX_LR = 1e-4\n",
    "NUM_EPOCHS = 20\n",
    "\n",
    "NUM_LSTM_LAYERS = 2\n",
    "EMBEDDING_DIM = 128\n",
    "HIDDEN_DIM = EMBEDDING_DIM // 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02ee8f9",
   "metadata": {
    "papermill": {
     "duration": 0.007049,
     "end_time": "2024-06-05T13:31:43.900920",
     "exception": false,
     "start_time": "2024-06-05T13:31:43.893871",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load the data and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86fc72f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T13:31:43.916300Z",
     "iopub.status.busy": "2024-06-05T13:31:43.915996Z",
     "iopub.status.idle": "2024-06-05T13:31:43.976695Z",
     "shell.execute_reply": "2024-06-05T13:31:43.975834Z"
    },
    "papermill": {
     "duration": 0.070471,
     "end_time": "2024-06-05T13:31:43.978669",
     "exception": false,
     "start_time": "2024-06-05T13:31:43.908198",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = Path('/kaggle/input/nlp-getting-started')\n",
    "train = pd.read_csv(data_path / 'train.csv')\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e20f8bca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T13:31:43.994529Z",
     "iopub.status.busy": "2024-06-05T13:31:43.994285Z",
     "iopub.status.idle": "2024-06-05T13:31:44.112736Z",
     "shell.execute_reply": "2024-06-05T13:31:44.112096Z"
    },
    "papermill": {
     "duration": 0.128553,
     "end_time": "2024-06-05T13:31:44.114612",
     "exception": false,
     "start_time": "2024-06-05T13:31:43.986059",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# remove emoticons\n",
    "# source: https://gist.github.com/slowkow/7a7f61f495e3dbb7e3d767f97bd7304b\n",
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string)\n",
    "\n",
    "# Preprocess the data\n",
    "def preprocess_tweet(tweet):\n",
    "    tweet = tweet.lower()\n",
    "    # remove urls\n",
    "    tweet = re.sub(r'http\\S+', '', tweet)\n",
    "    \n",
    "    # remove numbers\n",
    "    tweet = re.sub(r'[0-9]+(,[0-9])*(\\.[0-9]+)*', '', tweet)\n",
    "    \n",
    "    # remove emojis\n",
    "    tweet = remove_emoji(tweet)\n",
    "    \n",
    "    return tweet\n",
    "\n",
    "train['text'] = train['text'].apply(preprocess_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5450b015",
   "metadata": {
    "papermill": {
     "duration": 0.007337,
     "end_time": "2024-06-05T13:31:44.129492",
     "exception": false,
     "start_time": "2024-06-05T13:31:44.122155",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## WordPiece Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8d2071c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T13:31:44.145422Z",
     "iopub.status.busy": "2024-06-05T13:31:44.145177Z",
     "iopub.status.idle": "2024-06-05T13:31:44.158435Z",
     "shell.execute_reply": "2024-06-05T13:31:44.157624Z"
    },
    "papermill": {
     "duration": 0.023243,
     "end_time": "2024-06-05T13:31:44.160300",
     "exception": false,
     "start_time": "2024-06-05T13:31:44.137057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tokenizer with empty WordPiece model\n",
    "# unk_token - token for unknown words; using BERT convention\n",
    "tokenizer = Tokenizer(models.WordPiece(unk_token=\"[UNK]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "924660d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T13:31:44.176865Z",
     "iopub.status.busy": "2024-06-05T13:31:44.176604Z",
     "iopub.status.idle": "2024-06-05T13:31:44.180817Z",
     "shell.execute_reply": "2024-06-05T13:31:44.179985Z"
    },
    "papermill": {
     "duration": 0.014296,
     "end_time": "2024-06-05T13:31:44.182815",
     "exception": false,
     "start_time": "2024-06-05T13:31:44.168519",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# preprocessing steps\n",
    "# normalizer: NFD normalization, lower case, strip accents\n",
    "tokenizer.normalizer = normalizers.BertNormalizer(lowercase=True)\n",
    "\n",
    "# pre-tokenizer: split text using whitespace and punctuation\n",
    "tokenizer.pre_tokenizer = pre_tokenizers.BertPreTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "688b524f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T13:31:44.198765Z",
     "iopub.status.busy": "2024-06-05T13:31:44.198527Z",
     "iopub.status.idle": "2024-06-05T13:31:44.607800Z",
     "shell.execute_reply": "2024-06-05T13:31:44.606758Z"
    },
    "papermill": {
     "duration": 0.419428,
     "end_time": "2024-06-05T13:31:44.609752",
     "exception": false,
     "start_time": "2024-06-05T13:31:44.190324",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "special_tokens = [\"[UNK]\", \"[PAD]\"]\n",
    "trainer = trainers.WordPieceTrainer(\n",
    "    vocab_size=MAX_VOCAB_SIZE,\n",
    "    min_frequency=MIN_FREQUENCY,\n",
    "    special_tokens=special_tokens,\n",
    "    show_progress=True\n",
    ")\n",
    "\n",
    "tokenizer.train_from_iterator(train['text'].tolist(), trainer=trainer)\n",
    "\n",
    "# Optional: specifiy decoder\n",
    "tokenizer.decoder = decoders.WordPiece(prefix=\"##\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e216ee13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T13:31:44.626385Z",
     "iopub.status.busy": "2024-06-05T13:31:44.626087Z",
     "iopub.status.idle": "2024-06-05T13:31:44.630408Z",
     "shell.execute_reply": "2024-06-05T13:31:44.629684Z"
    },
    "papermill": {
     "duration": 0.014557,
     "end_time": "2024-06-05T13:31:44.632256",
     "exception": false,
     "start_time": "2024-06-05T13:31:44.617699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the tokenizer\n",
    "tokenizer.save(\"wordpiece_tokenizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cacd5aa",
   "metadata": {
    "papermill": {
     "duration": 0.007528,
     "end_time": "2024-06-05T13:31:44.647782",
     "exception": false,
     "start_time": "2024-06-05T13:31:44.640254",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Pretraining token embeddings using fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e794082",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T13:31:44.663856Z",
     "iopub.status.busy": "2024-06-05T13:31:44.663591Z",
     "iopub.status.idle": "2024-06-05T13:31:53.263183Z",
     "shell.execute_reply": "2024-06-05T13:31:53.262207Z"
    },
    "papermill": {
     "duration": 8.609903,
     "end_time": "2024-06-05T13:31:53.265143",
     "exception": false,
     "start_time": "2024-06-05T13:31:44.655240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  3265\n",
      "Number of labels: 0\n",
      "Progress: 100.0% words/sec/thread:   52180 lr:  0.000000 avg.loss:  2.582424 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "# Save tokenized texts to a file\n",
    "with open(\"tokenized_texts.txt\", \"w\") as f:\n",
    "    for text in train['text']:\n",
    "        f.write(\" \".join(tokenizer.encode(text).tokens) + \"\\n\")\n",
    "        \n",
    "# Train FastText model \n",
    "fasttext_model = fasttext.train_unsupervised('tokenized_texts.txt', model='skipgram', dim=EMBEDDING_DIM)\n",
    "\n",
    "# Save the model \n",
    "fasttext_model.save_model(\"fasttext_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca7e5259",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T13:31:53.286116Z",
     "iopub.status.busy": "2024-06-05T13:31:53.285430Z",
     "iopub.status.idle": "2024-06-05T13:31:53.366420Z",
     "shell.execute_reply": "2024-06-05T13:31:53.365682Z"
    },
    "papermill": {
     "duration": 0.093703,
     "end_time": "2024-06-05T13:31:53.368598",
     "exception": false,
     "start_time": "2024-06-05T13:31:53.274895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create an embedding matrix\n",
    "vocab_size = tokenizer.get_vocab_size()\n",
    "embedding_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\n",
    "\n",
    "# Initialize the embedding matrix with FastText vectors\n",
    "for word, idx in tokenizer.get_vocab().items():\n",
    "    embedding_matrix[idx] = fasttext_model.get_word_vector(word)\n",
    "    \n",
    "# Convert embedding matrix to a tensor\n",
    "embedding_matrix = torch.tensor(embedding_matrix, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6731ee",
   "metadata": {
    "papermill": {
     "duration": 0.009297,
     "end_time": "2024-06-05T13:31:53.388798",
     "exception": false,
     "start_time": "2024-06-05T13:31:53.379501",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training and Validation Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fe3e608",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T13:31:53.409431Z",
     "iopub.status.busy": "2024-06-05T13:31:53.408701Z",
     "iopub.status.idle": "2024-06-05T13:31:53.419027Z",
     "shell.execute_reply": "2024-06-05T13:31:53.418329Z"
    },
    "papermill": {
     "duration": 0.022469,
     "end_time": "2024-06-05T13:31:53.420878",
     "exception": false,
     "start_time": "2024-06-05T13:31:53.398409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pad_to\n",
    "pad_token_id = tokenizer.token_to_id(\"[PAD]\")\n",
    "\n",
    "\n",
    "# Function to pad and truncate sequences\n",
    "def pad_and_truncate(sequence, max_length, pad_token_id):\n",
    "    if len(sequence) > max_length:\n",
    "        return sequence[:max_length]\n",
    "    return sequence + [pad_token_id] * (max_length - len(sequence))\n",
    "\n",
    "\n",
    "class TweetDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, pad_token_id):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.pad_token_id = pad_token_id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        tokenized_text = self.tokenizer.encode(text).ids\n",
    "        return torch.tensor(tokenized_text), torch.tensor(label)\n",
    "\n",
    "# Custom collate function for dynamic padding\n",
    "def collate_fn(batch):\n",
    "    texts, labels = zip(*batch)\n",
    "    \n",
    "    # Compute max length in the batch\n",
    "    max_length = max(MAX_SEQ_LEN, max(len(text) for text in texts))\n",
    "    \n",
    "    # Pad sequences to the max length\n",
    "    padded_texts = [pad_and_truncate(text.tolist(), max_length, pad_token_id) for text in texts]\n",
    "    \n",
    "    # Convert to tensors\n",
    "    padded_texts = torch.tensor(padded_texts)\n",
    "    labels = torch.tensor(labels)\n",
    "    \n",
    "    return padded_texts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a1ed6c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T13:31:53.440581Z",
     "iopub.status.busy": "2024-06-05T13:31:53.440342Z",
     "iopub.status.idle": "2024-06-05T13:31:53.451893Z",
     "shell.execute_reply": "2024-06-05T13:31:53.451205Z"
    },
    "papermill": {
     "duration": 0.023383,
     "end_time": "2024-06-05T13:31:53.453625",
     "exception": false,
     "start_time": "2024-06-05T13:31:53.430242",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# split into trainining and validation datasets\n",
    "train_tweets, val_tweets, train_labels, val_labels = train_test_split(\n",
    "    train['text'].tolist(), train['target'].tolist(), test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = TweetDataset(train_tweets, train_labels, tokenizer, pad_token_id)\n",
    "val_dataset = TweetDataset(val_tweets, val_labels, tokenizer, pad_token_id)\n",
    "\n",
    "# Create dataloaders with custom collate function\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b11551",
   "metadata": {
    "papermill": {
     "duration": 0.009293,
     "end_time": "2024-06-05T13:31:53.472329",
     "exception": false,
     "start_time": "2024-06-05T13:31:53.463036",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## LSTM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35c8fc17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T13:31:53.492553Z",
     "iopub.status.busy": "2024-06-05T13:31:53.491861Z",
     "iopub.status.idle": "2024-06-05T13:31:53.502114Z",
     "shell.execute_reply": "2024-06-05T13:31:53.501369Z"
    },
    "papermill": {
     "duration": 0.022089,
     "end_time": "2024-06-05T13:31:53.503930",
     "exception": false,
     "start_time": "2024-06-05T13:31:53.481841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BiLSTMClassifier(nn.Module):\n",
    "    def __init__(\n",
    "        self, vocab_size, embedding_dim, hidden_dim, num_lstm_layers, \n",
    "        output_dim, pad_token_id,\n",
    "        embedding_matrix=None\n",
    "    ):\n",
    "        super(BiLSTMClassifier, self).__init__()\n",
    "        if embedding_matrix is not None:\n",
    "            self.embedding = nn.Embedding.from_pretrained(embedding_matrix, freeze=False, padding_idx=pad_token_id)\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_token_id)\n",
    "        self.lstm_layers = nn.ModuleList([\n",
    "            nn.LSTM(\n",
    "                embedding_dim if i == 0 else hidden_dim * 2,\n",
    "                hidden_dim,\n",
    "                num_layers=1,\n",
    "                bidirectional=True,\n",
    "                batch_first=True\n",
    "            ) for i in range(num_lstm_layers)\n",
    "        ])\n",
    "        \n",
    "        \n",
    "        self.lstm_dropout = nn.Dropout(0.2)\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(128, output_dim)\n",
    "        )\n",
    "        self.pad_token_id = pad_token_id\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)\n",
    "        x = embedded\n",
    "        \n",
    "        for lstm in self.lstm_layers:\n",
    "            lstm_out, _ = lstm(x)\n",
    "            x = x + lstm_out\n",
    "        \n",
    "        # Create mask for padding tokens\n",
    "        mask = (text != self.pad_token_id).unsqueeze(2).type(torch.float32)\n",
    "        \n",
    "        # Apply mask to LSTM outputs\n",
    "        masked_lstm_out = lstm_out * mask\n",
    "        \n",
    "        # Sum the outputs and divide by the number of valid (non-pad) tokens\n",
    "        pooled = masked_lstm_out.sum(dim=1) / mask.sum(dim=1)\n",
    "        \n",
    "        output = self.lstm_dropout(pooled)\n",
    "        return self.fc(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d716ba8",
   "metadata": {
    "papermill": {
     "duration": 0.009194,
     "end_time": "2024-06-05T13:31:53.522492",
     "exception": false,
     "start_time": "2024-06-05T13:31:53.513298",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de35f8d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T13:31:53.542639Z",
     "iopub.status.busy": "2024-06-05T13:31:53.542194Z",
     "iopub.status.idle": "2024-06-05T13:31:53.553354Z",
     "shell.execute_reply": "2024-06-05T13:31:53.552558Z"
    },
    "papermill": {
     "duration": 0.023377,
     "end_time": "2024-06-05T13:31:53.555144",
     "exception": false,
     "start_time": "2024-06-05T13:31:53.531767",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, epochs=5, checkpoint_path='best_model.pth'):\n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        # Create a progress bar for the entire epoch\n",
    "        pbar = tqdm(total=len(train_loader), desc=f'Epoch {epoch + 1}/{epochs}', unit='batch')\n",
    "\n",
    "        for texts, labels in train_loader:\n",
    "            texts, labels = texts.to(device), labels.to(device).float()\n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(texts).squeeze(1)\n",
    "            loss = criterion(predictions, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()  # Update the learning rate\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            pbar.set_postfix({'Train Loss': epoch_loss / (pbar.n + 1)})\n",
    "            pbar.update()\n",
    "\n",
    "        pbar.close()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for texts, labels in val_loader:\n",
    "                texts, labels = texts.to(device), labels.to(device).float()\n",
    "                predictions = model(texts).squeeze(1)\n",
    "                loss = criterion(predictions, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        print(f'Epoch {epoch + 1}, Train Loss: {epoch_loss / len(train_loader):.4f}, Validation Loss: {val_loss:.4f}')\n",
    "\n",
    "        # Reopen progress bar for next epoch\n",
    "        tqdm.write(f'Epoch {epoch + 1} completed. Train Loss: {epoch_loss / len(train_loader):.4f}, Validation Loss: {val_loss:.4f}')\n",
    "        \n",
    "        # Checkpoint the model if validation loss decreases\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "            print(f'Saved Best Model at Epoch {epoch + 1} with Validation Loss: {val_loss:.4f}')\n",
    "            \n",
    "        \n",
    "    # set to best checkpoint\n",
    "    model.load_state_dict(torch.load(checkpoint_path))\n",
    "    print(f'Best validation loss: {best_val_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebe6115f",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-06-05T13:31:53.575062Z",
     "iopub.status.busy": "2024-06-05T13:31:53.574528Z",
     "iopub.status.idle": "2024-06-05T13:32:21.139522Z",
     "shell.execute_reply": "2024-06-05T13:32:21.138416Z"
    },
    "papermill": {
     "duration": 27.577057,
     "end_time": "2024-06-05T13:32:21.141574",
     "exception": false,
     "start_time": "2024-06-05T13:31:53.564517",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████| 48/48 [00:01<00:00, 24.10batch/s, Train Loss=0.685]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.6853, Validation Loss: 0.6756\n",
      "Epoch 1 completed. Train Loss: 0.6853, Validation Loss: 0.6756\n",
      "Saved Best Model at Epoch 1 with Validation Loss: 0.6756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|██████████| 48/48 [00:01<00:00, 45.93batch/s, Train Loss=0.669]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 0.6687, Validation Loss: 0.6179\n",
      "Epoch 2 completed. Train Loss: 0.6687, Validation Loss: 0.6179\n",
      "Saved Best Model at Epoch 2 with Validation Loss: 0.6179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|██████████| 48/48 [00:01<00:00, 46.78batch/s, Train Loss=0.634]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 0.6336, Validation Loss: 0.5842\n",
      "Epoch 3 completed. Train Loss: 0.6336, Validation Loss: 0.5842\n",
      "Saved Best Model at Epoch 3 with Validation Loss: 0.5842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|██████████| 48/48 [00:01<00:00, 46.68batch/s, Train Loss=0.592]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 0.5924, Validation Loss: 0.5620\n",
      "Epoch 4 completed. Train Loss: 0.5924, Validation Loss: 0.5620\n",
      "Saved Best Model at Epoch 4 with Validation Loss: 0.5620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|██████████| 48/48 [00:01<00:00, 45.15batch/s, Train Loss=0.571]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 0.5709, Validation Loss: 0.5481\n",
      "Epoch 5 completed. Train Loss: 0.5709, Validation Loss: 0.5481\n",
      "Saved Best Model at Epoch 5 with Validation Loss: 0.5481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|██████████| 48/48 [00:01<00:00, 45.94batch/s, Train Loss=0.556]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train Loss: 0.5557, Validation Loss: 0.5310\n",
      "Epoch 6 completed. Train Loss: 0.5557, Validation Loss: 0.5310\n",
      "Saved Best Model at Epoch 6 with Validation Loss: 0.5310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|██████████| 48/48 [00:01<00:00, 46.33batch/s, Train Loss=0.537]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train Loss: 0.5371, Validation Loss: 0.5144\n",
      "Epoch 7 completed. Train Loss: 0.5371, Validation Loss: 0.5144\n",
      "Saved Best Model at Epoch 7 with Validation Loss: 0.5144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|██████████| 48/48 [00:01<00:00, 45.46batch/s, Train Loss=0.506]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 0.5055, Validation Loss: 0.5010\n",
      "Epoch 8 completed. Train Loss: 0.5055, Validation Loss: 0.5010\n",
      "Saved Best Model at Epoch 8 with Validation Loss: 0.5010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|██████████| 48/48 [00:01<00:00, 42.28batch/s, Train Loss=0.464]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Train Loss: 0.4635, Validation Loss: 0.4819\n",
      "Epoch 9 completed. Train Loss: 0.4635, Validation Loss: 0.4819\n",
      "Saved Best Model at Epoch 9 with Validation Loss: 0.4819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|██████████| 48/48 [00:01<00:00, 43.10batch/s, Train Loss=0.404]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 0.4041, Validation Loss: 0.4429\n",
      "Epoch 10 completed. Train Loss: 0.4041, Validation Loss: 0.4429\n",
      "Saved Best Model at Epoch 10 with Validation Loss: 0.4429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|██████████| 48/48 [00:01<00:00, 44.83batch/s, Train Loss=0.357]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Train Loss: 0.3566, Validation Loss: 0.4495\n",
      "Epoch 11 completed. Train Loss: 0.3566, Validation Loss: 0.4495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|██████████| 48/48 [00:01<00:00, 43.84batch/s, Train Loss=0.319]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Train Loss: 0.3188, Validation Loss: 0.4427\n",
      "Epoch 12 completed. Train Loss: 0.3188, Validation Loss: 0.4427\n",
      "Saved Best Model at Epoch 12 with Validation Loss: 0.4427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|██████████| 48/48 [00:01<00:00, 44.60batch/s, Train Loss=0.291]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Train Loss: 0.2912, Validation Loss: 0.4665\n",
      "Epoch 13 completed. Train Loss: 0.2912, Validation Loss: 0.4665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 100%|██████████| 48/48 [00:01<00:00, 42.93batch/s, Train Loss=0.274]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Train Loss: 0.2739, Validation Loss: 0.4607\n",
      "Epoch 14 completed. Train Loss: 0.2739, Validation Loss: 0.4607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|██████████| 48/48 [00:01<00:00, 44.78batch/s, Train Loss=0.266]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Train Loss: 0.2656, Validation Loss: 0.4747\n",
      "Epoch 15 completed. Train Loss: 0.2656, Validation Loss: 0.4747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 100%|██████████| 48/48 [00:01<00:00, 45.12batch/s, Train Loss=0.252]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Train Loss: 0.2520, Validation Loss: 0.4767\n",
      "Epoch 16 completed. Train Loss: 0.2520, Validation Loss: 0.4767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 100%|██████████| 48/48 [00:01<00:00, 44.82batch/s, Train Loss=0.245]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Train Loss: 0.2454, Validation Loss: 0.4860\n",
      "Epoch 17 completed. Train Loss: 0.2454, Validation Loss: 0.4860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: 100%|██████████| 48/48 [00:01<00:00, 45.58batch/s, Train Loss=0.242]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Train Loss: 0.2424, Validation Loss: 0.4819\n",
      "Epoch 18 completed. Train Loss: 0.2424, Validation Loss: 0.4819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: 100%|██████████| 48/48 [00:01<00:00, 43.72batch/s, Train Loss=0.244]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Train Loss: 0.2439, Validation Loss: 0.4836\n",
      "Epoch 19 completed. Train Loss: 0.2439, Validation Loss: 0.4836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|██████████| 48/48 [00:01<00:00, 44.36batch/s, Train Loss=0.237]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Train Loss: 0.2367, Validation Loss: 0.4882\n",
      "Epoch 20 completed. Train Loss: 0.2367, Validation Loss: 0.4882\n",
      "Best validation loss: 0.4427\n"
     ]
    }
   ],
   "source": [
    "# Model parameters\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "vocab_size = tokenizer.get_vocab_size()\n",
    "\n",
    "# Set up the model, optimizer, and criterion\n",
    "model = BiLSTMClassifier(\n",
    "    vocab_size, EMBEDDING_DIM, HIDDEN_DIM, NUM_LSTM_LAYERS, 1,  pad_token_id,\n",
    "    embedding_matrix=embedding_matrix\n",
    ").to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)  # Set initial LR for the optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Setup OneCycleLR\n",
    "total_steps = len(train_loader) * NUM_EPOCHS # total training steps = num_epochs * batches_per_epoch\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=MAX_LR, total_steps=total_steps)\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, epochs=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4856bb45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T13:32:21.349065Z",
     "iopub.status.busy": "2024-06-05T13:32:21.348577Z",
     "iopub.status.idle": "2024-06-05T13:32:21.589293Z",
     "shell.execute_reply": "2024-06-05T13:32:21.588012Z"
    },
    "papermill": {
     "duration": 0.346637,
     "end_time": "2024-06-05T13:32:21.591632",
     "exception": false,
     "start_time": "2024-06-05T13:32:21.244995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8102, F1: 0.7652, ROC AUC: 0.8656\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, val_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    with torch.no_grad():\n",
    "        for texts, labels in val_loader:\n",
    "            texts, labels = texts.to(device), labels.to(device).float()\n",
    "            predictions = model(texts).squeeze(1)\n",
    "            probs = torch.sigmoid(predictions)\n",
    "            preds = torch.round(probs)\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    roc_auc = roc_auc_score(all_labels, all_probs)\n",
    "    return accuracy, f1, roc_auc\n",
    "\n",
    "# Example of evaluating the model\n",
    "accuracy, f1, roc_auc = evaluate_model(model, val_loader)\n",
    "print(f'Accuracy: {accuracy:.4f}, F1: {f1:.4f}, ROC AUC: {roc_auc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a543392c",
   "metadata": {
    "papermill": {
     "duration": 0.190689,
     "end_time": "2024-06-05T13:32:21.921510",
     "exception": false,
     "start_time": "2024-06-05T13:32:21.730821",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Test predictions and submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c078003",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T13:32:22.201279Z",
     "iopub.status.busy": "2024-06-05T13:32:22.200735Z",
     "iopub.status.idle": "2024-06-05T13:32:22.281588Z",
     "shell.execute_reply": "2024-06-05T13:32:22.280789Z"
    },
    "papermill": {
     "duration": 0.224894,
     "end_time": "2024-06-05T13:32:22.283666",
     "exception": false,
     "start_time": "2024-06-05T13:32:22.058772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer, max_length, pad_token_id):\n",
    "        self.texts = texts\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.pad_token_id = pad_token_id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        tokenized_text = self.tokenizer.encode(text).ids\n",
    "        padded_text = pad_and_truncate(tokenized_text, self.max_length, self.pad_token_id)\n",
    "        return torch.tensor(padded_text)\n",
    "\n",
    "test = pd.read_csv(data_path / 'test.csv')\n",
    "test['text'] = test['text'].apply(preprocess_tweet)\n",
    "\n",
    "# Create the test dataset\n",
    "test_dataset = TestDataset(test['text'].tolist(), tokenizer, MAX_SEQ_LEN, pad_token_id)\n",
    "\n",
    "# Create the test DataLoader\n",
    "test_loader = DataLoader(test_dataset, batch_size=1024, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bfb8ecf2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T13:32:22.508330Z",
     "iopub.status.busy": "2024-06-05T13:32:22.507530Z",
     "iopub.status.idle": "2024-06-05T13:32:22.896781Z",
     "shell.execute_reply": "2024-06-05T13:32:22.895896Z"
    },
    "papermill": {
     "duration": 0.509841,
     "end_time": "2024-06-05T13:32:22.898901",
     "exception": false,
     "start_time": "2024-06-05T13:32:22.389060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 10.54it/s]\n"
     ]
    }
   ],
   "source": [
    "def generate_predictions(model, test_loader):\n",
    "    model.eval()\n",
    "    all_probs = []\n",
    "    with torch.no_grad():\n",
    "        for texts in tqdm(test_loader):\n",
    "            texts = texts.to(device)\n",
    "            predictions = model(texts).squeeze(1)\n",
    "            probs = torch.sigmoid(predictions)\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "    return all_probs\n",
    "\n",
    "# Generate predictions on the test set\n",
    "test_predictions = generate_predictions(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "482ed121",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T13:32:23.118065Z",
     "iopub.status.busy": "2024-06-05T13:32:23.117234Z",
     "iopub.status.idle": "2024-06-05T13:32:23.136039Z",
     "shell.execute_reply": "2024-06-05T13:32:23.135144Z"
    },
    "papermill": {
     "duration": 0.129198,
     "end_time": "2024-06-05T13:32:23.137943",
     "exception": false,
     "start_time": "2024-06-05T13:32:23.008745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target\n",
       "0   0       1\n",
       "1   2       0\n",
       "2   3       1\n",
       "3   9       1\n",
       "4  11       1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame({'id':test['id'],'target':test_predictions})\n",
    "submission['target'] = submission['target'].round().astype(int)\n",
    "submission.to_csv('submission.csv',index=False)\n",
    "submission.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cb8fd6",
   "metadata": {
    "papermill": {
     "duration": 0.103887,
     "end_time": "2024-06-05T13:32:23.346402",
     "exception": false,
     "start_time": "2024-06-05T13:32:23.242515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 869809,
     "sourceId": 17777,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 51.599564,
   "end_time": "2024-06-05T13:32:25.072542",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-05T13:31:33.472978",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
