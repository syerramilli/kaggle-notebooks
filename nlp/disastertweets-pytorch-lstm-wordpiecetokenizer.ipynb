{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53a9d419",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-05-30T22:01:14.222187Z",
     "iopub.status.busy": "2024-05-30T22:01:14.221844Z",
     "iopub.status.idle": "2024-05-30T22:01:21.532698Z",
     "shell.execute_reply": "2024-05-30T22:01:21.531671Z"
    },
    "papermill": {
     "duration": 7.321443,
     "end_time": "2024-05-30T22:01:21.534992",
     "exception": false,
     "start_time": "2024-05-30T22:01:14.213549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from tokenizers import decoders, models, normalizers, pre_tokenizers, processors, trainers, Tokenizer\n",
    "from transformers import BertTokenizerFast\n",
    "\n",
    "from pathlib import Path\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e55a503a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T22:01:21.549562Z",
     "iopub.status.busy": "2024-05-30T22:01:21.549072Z",
     "iopub.status.idle": "2024-05-30T22:01:21.553840Z",
     "shell.execute_reply": "2024-05-30T22:01:21.552988Z"
    },
    "papermill": {
     "duration": 0.014087,
     "end_time": "2024-05-30T22:01:21.555812",
     "exception": false,
     "start_time": "2024-05-30T22:01:21.541725",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## CONFIG\n",
    "VOCAB_SIZE = 5000\n",
    "MIN_FREQUENCY = 10\n",
    "MAX_SEQ_LEN = 50\n",
    "BATCH_SIZE = 256\n",
    "MAX_LR = 5e-4\n",
    "NUM_EPOCHS = 20\n",
    "NUM_LSTM_LAYERS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3c7a81",
   "metadata": {
    "papermill": {
     "duration": 0.0061,
     "end_time": "2024-05-30T22:01:21.568182",
     "exception": false,
     "start_time": "2024-05-30T22:01:21.562082",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load the data and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6fb0607",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T22:01:21.581840Z",
     "iopub.status.busy": "2024-05-30T22:01:21.581551Z",
     "iopub.status.idle": "2024-05-30T22:01:21.641754Z",
     "shell.execute_reply": "2024-05-30T22:01:21.640837Z"
    },
    "papermill": {
     "duration": 0.069251,
     "end_time": "2024-05-30T22:01:21.643679",
     "exception": false,
     "start_time": "2024-05-30T22:01:21.574428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = Path('/kaggle/input/nlp-getting-started')\n",
    "train = pd.read_csv(data_path / 'train.csv')\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "061a77b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T22:01:21.658325Z",
     "iopub.status.busy": "2024-05-30T22:01:21.658011Z",
     "iopub.status.idle": "2024-05-30T22:01:21.724769Z",
     "shell.execute_reply": "2024-05-30T22:01:21.724014Z"
    },
    "papermill": {
     "duration": 0.076343,
     "end_time": "2024-05-30T22:01:21.726751",
     "exception": false,
     "start_time": "2024-05-30T22:01:21.650408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "def preprocess_tweet(tweet):\n",
    "    tweet = tweet.lower()\n",
    "    # remove urls\n",
    "    tweet = re.sub(r'http\\S+', '', tweet)\n",
    "    tweet = re.sub(r'www\\S+', '', tweet)\n",
    "    \n",
    "    # remove numbers\n",
    "    tweet = re.sub(r'[0-9]+(,[0-9])*(\\.[0-9]+)*', '', tweet)\n",
    "    return tweet\n",
    "\n",
    "train['text'] = train['text'].apply(preprocess_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32efc132",
   "metadata": {
    "papermill": {
     "duration": 0.006384,
     "end_time": "2024-05-30T22:01:21.740006",
     "exception": false,
     "start_time": "2024-05-30T22:01:21.733622",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## WordPiece Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9c84983",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T22:01:21.754255Z",
     "iopub.status.busy": "2024-05-30T22:01:21.753960Z",
     "iopub.status.idle": "2024-05-30T22:01:21.764288Z",
     "shell.execute_reply": "2024-05-30T22:01:21.763549Z"
    },
    "papermill": {
     "duration": 0.019414,
     "end_time": "2024-05-30T22:01:21.766018",
     "exception": false,
     "start_time": "2024-05-30T22:01:21.746604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tokenizer with empty WordPiece model\n",
    "# unk_token - token for unknown words; using BERT convention\n",
    "tokenizer = Tokenizer(models.WordPiece(unk_token=\"[UNK]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc584f58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T22:01:21.780183Z",
     "iopub.status.busy": "2024-05-30T22:01:21.779900Z",
     "iopub.status.idle": "2024-05-30T22:01:21.784147Z",
     "shell.execute_reply": "2024-05-30T22:01:21.783327Z"
    },
    "papermill": {
     "duration": 0.01365,
     "end_time": "2024-05-30T22:01:21.786197",
     "exception": false,
     "start_time": "2024-05-30T22:01:21.772547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# preprocessing steps\n",
    "# normalizer: NFD normalization, lower case, strip accents\n",
    "tokenizer.normalizer = normalizers.BertNormalizer(lowercase=True)\n",
    "\n",
    "# pre-tokenizer: split text using whitespace and punctuation\n",
    "tokenizer.pre_tokenizer = pre_tokenizers.BertPreTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5093b9af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T22:01:21.800377Z",
     "iopub.status.busy": "2024-05-30T22:01:21.800018Z",
     "iopub.status.idle": "2024-05-30T22:01:22.293882Z",
     "shell.execute_reply": "2024-05-30T22:01:22.292927Z"
    },
    "papermill": {
     "duration": 0.503215,
     "end_time": "2024-05-30T22:01:22.295887",
     "exception": false,
     "start_time": "2024-05-30T22:01:21.792672",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "special_tokens = [\"[UNK]\", \"[PAD]\"]\n",
    "trainer = trainers.WordPieceTrainer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    min_frequency=MIN_FREQUENCY,\n",
    "    special_tokens=special_tokens,\n",
    "    show_progress=True\n",
    ")\n",
    "\n",
    "tokenizer.train_from_iterator(train['text'].tolist(), trainer=trainer)\n",
    "\n",
    "# Optional: specifiy decoder\n",
    "tokenizer.decoder = decoders.WordPiece(prefix=\"##\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f74d47f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T22:01:22.311673Z",
     "iopub.status.busy": "2024-05-30T22:01:22.310769Z",
     "iopub.status.idle": "2024-05-30T22:01:22.316037Z",
     "shell.execute_reply": "2024-05-30T22:01:22.315193Z"
    },
    "papermill": {
     "duration": 0.01551,
     "end_time": "2024-05-30T22:01:22.318456",
     "exception": false,
     "start_time": "2024-05-30T22:01:22.302946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the tokenizer\n",
    "tokenizer.save(\"wordpiece_tokenizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca49bc3",
   "metadata": {
    "papermill": {
     "duration": 0.008036,
     "end_time": "2024-05-30T22:01:22.335725",
     "exception": false,
     "start_time": "2024-05-30T22:01:22.327689",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training and Validation Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4aa26f15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T22:01:22.350561Z",
     "iopub.status.busy": "2024-05-30T22:01:22.350289Z",
     "iopub.status.idle": "2024-05-30T22:01:22.359955Z",
     "shell.execute_reply": "2024-05-30T22:01:22.359106Z"
    },
    "papermill": {
     "duration": 0.019376,
     "end_time": "2024-05-30T22:01:22.361851",
     "exception": false,
     "start_time": "2024-05-30T22:01:22.342475",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pad_to\n",
    "pad_token_id = tokenizer.token_to_id(\"[PAD]\")\n",
    "\n",
    "\n",
    "# Function to pad and truncate sequences\n",
    "def pad_and_truncate(sequence, max_length, pad_token_id):\n",
    "    if len(sequence) > max_length:\n",
    "        return sequence[:max_length]\n",
    "    return sequence + [pad_token_id] * (max_length - len(sequence))\n",
    "\n",
    "\n",
    "class TweetDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, pad_token_id):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.pad_token_id = pad_token_id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        tokenized_text = self.tokenizer.encode(text).ids\n",
    "        return torch.tensor(tokenized_text), torch.tensor(label)\n",
    "\n",
    "# Custom collate function for dynamic padding\n",
    "def collate_fn(batch):\n",
    "    texts, labels = zip(*batch)\n",
    "    \n",
    "    # Compute max length in the batch\n",
    "    max_length = max(MAX_SEQ_LEN, max(len(text) for text in texts))\n",
    "    \n",
    "    # Pad sequences to the max length\n",
    "    padded_texts = [pad_and_truncate(text.tolist(), max_length, pad_token_id) for text in texts]\n",
    "    \n",
    "    # Convert to tensors\n",
    "    padded_texts = torch.tensor(padded_texts)\n",
    "    labels = torch.tensor(labels)\n",
    "    \n",
    "    return padded_texts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2f41136",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T22:01:22.376793Z",
     "iopub.status.busy": "2024-05-30T22:01:22.376214Z",
     "iopub.status.idle": "2024-05-30T22:01:22.391584Z",
     "shell.execute_reply": "2024-05-30T22:01:22.390760Z"
    },
    "papermill": {
     "duration": 0.024885,
     "end_time": "2024-05-30T22:01:22.393499",
     "exception": false,
     "start_time": "2024-05-30T22:01:22.368614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# split into trainining and validation datasets\n",
    "train_tweets, val_tweets, train_labels, val_labels = train_test_split(\n",
    "    train['text'].tolist(), train['target'].tolist(), test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = TweetDataset(train_tweets, train_labels, tokenizer, pad_token_id)\n",
    "val_dataset = TweetDataset(val_tweets, val_labels, tokenizer, pad_token_id)\n",
    "\n",
    "# Create dataloaders with custom collate function\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22362f66",
   "metadata": {
    "papermill": {
     "duration": 0.006475,
     "end_time": "2024-05-30T22:01:22.406836",
     "exception": false,
     "start_time": "2024-05-30T22:01:22.400361",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## LSTM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20ff098b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T22:01:22.422749Z",
     "iopub.status.busy": "2024-05-30T22:01:22.421888Z",
     "iopub.status.idle": "2024-05-30T22:01:22.432496Z",
     "shell.execute_reply": "2024-05-30T22:01:22.431634Z"
    },
    "papermill": {
     "duration": 0.020523,
     "end_time": "2024-05-30T22:01:22.434450",
     "exception": false,
     "start_time": "2024-05-30T22:01:22.413927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BiLSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, pad_token_id):\n",
    "        super(BiLSTMClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_token_id)\n",
    "        self.lstm = nn.LSTM(\n",
    "            embedding_dim, hidden_dim, \n",
    "            num_layers=NUM_LSTM_LAYERS,\n",
    "            bidirectional=True, \n",
    "            batch_first=True)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.pad_token_id = pad_token_id\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)\n",
    "        lstm_out, _ = self.lstm(embedded)\n",
    "        \n",
    "        # Create mask for padding tokens\n",
    "        mask = (text != self.pad_token_id).unsqueeze(2).type(torch.float32)\n",
    "        \n",
    "        # Apply mask to LSTM outputs\n",
    "        masked_lstm_out = lstm_out * mask\n",
    "        \n",
    "        # Sum the outputs and divide by the number of valid (non-pad) tokens\n",
    "        pooled = masked_lstm_out.sum(dim=1) / mask.sum(dim=1)\n",
    "        \n",
    "        output = self.dropout(pooled)\n",
    "        return self.fc(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3914231",
   "metadata": {
    "papermill": {
     "duration": 0.00657,
     "end_time": "2024-05-30T22:01:22.447778",
     "exception": false,
     "start_time": "2024-05-30T22:01:22.441208",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d242c29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T22:01:22.466043Z",
     "iopub.status.busy": "2024-05-30T22:01:22.465728Z",
     "iopub.status.idle": "2024-05-30T22:01:22.475920Z",
     "shell.execute_reply": "2024-05-30T22:01:22.474990Z"
    },
    "papermill": {
     "duration": 0.022453,
     "end_time": "2024-05-30T22:01:22.478401",
     "exception": false,
     "start_time": "2024-05-30T22:01:22.455948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, epochs=5):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        model.train()\n",
    "        \n",
    "        # Create a progress bar for training\n",
    "        with tqdm(total=len(train_loader), desc=f'Epoch {epoch + 1}/{epochs}', unit='batch') as pbar:\n",
    "            for texts, labels in train_loader:\n",
    "                texts, labels = texts.to(device), labels.to(device).float()\n",
    "                optimizer.zero_grad()\n",
    "                predictions = model(texts).squeeze(1)\n",
    "                loss = criterion(predictions, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                scheduler.step()  # Update the learning rate\n",
    "                \n",
    "                epoch_loss += loss.item()\n",
    "                pbar.set_postfix({'Train Loss': epoch_loss / (pbar.n + 1)})\n",
    "                pbar.update()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            with tqdm(total=len(val_loader), desc='Validating', unit='batch') as pbar:\n",
    "                for texts, labels in val_loader:\n",
    "                    texts, labels = texts.to(device), labels.to(device).float()\n",
    "                    predictions = model(texts).squeeze(1)\n",
    "                    loss = criterion(predictions, labels)\n",
    "                    val_loss += loss.item()\n",
    "                    pbar.set_postfix({'Validation Loss': val_loss / (pbar.n + 1)})\n",
    "                    pbar.update()\n",
    "        \n",
    "        # Log epoch losses\n",
    "        #print(f'Epoch {epoch + 1}, Train Loss: {epoch_loss / len(train_loader)}, Validation Loss: {val_loss / len(val_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1589d76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T22:01:22.498536Z",
     "iopub.status.busy": "2024-05-30T22:01:22.498046Z",
     "iopub.status.idle": "2024-05-30T22:02:04.796983Z",
     "shell.execute_reply": "2024-05-30T22:02:04.796059Z"
    },
    "papermill": {
     "duration": 42.311066,
     "end_time": "2024-05-30T22:02:04.799199",
     "exception": false,
     "start_time": "2024-05-30T22:01:22.488133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████| 24/24 [00:02<00:00,  8.56batch/s, Train Loss=0.695]\n",
      "Validating: 100%|██████████| 6/6 [00:00<00:00, 18.62batch/s, Validation Loss=0.692]\n",
      "Epoch 2/20: 100%|██████████| 24/24 [00:01<00:00, 14.04batch/s, Train Loss=0.688]\n",
      "Validating: 100%|██████████| 6/6 [00:00<00:00, 21.45batch/s, Validation Loss=0.681]\n",
      "Epoch 3/20: 100%|██████████| 24/24 [00:01<00:00, 14.09batch/s, Train Loss=0.672]\n",
      "Validating: 100%|██████████| 6/6 [00:00<00:00, 20.15batch/s, Validation Loss=0.647]\n",
      "Epoch 4/20: 100%|██████████| 24/24 [00:01<00:00, 13.98batch/s, Train Loss=0.614]\n",
      "Validating: 100%|██████████| 6/6 [00:00<00:00, 20.94batch/s, Validation Loss=0.596]\n",
      "Epoch 5/20: 100%|██████████| 24/24 [00:01<00:00, 14.04batch/s, Train Loss=0.547]\n",
      "Validating: 100%|██████████| 6/6 [00:00<00:00, 20.66batch/s, Validation Loss=0.56]\n",
      "Epoch 6/20: 100%|██████████| 24/24 [00:01<00:00, 13.94batch/s, Train Loss=0.498]\n",
      "Validating: 100%|██████████| 6/6 [00:00<00:00, 21.51batch/s, Validation Loss=0.533]\n",
      "Epoch 7/20: 100%|██████████| 24/24 [00:01<00:00, 14.19batch/s, Train Loss=0.44]\n",
      "Validating: 100%|██████████| 6/6 [00:00<00:00, 21.57batch/s, Validation Loss=0.538]\n",
      "Epoch 8/20: 100%|██████████| 24/24 [00:01<00:00, 13.75batch/s, Train Loss=0.375]\n",
      "Validating: 100%|██████████| 6/6 [00:00<00:00, 20.62batch/s, Validation Loss=0.552]\n",
      "Epoch 9/20: 100%|██████████| 24/24 [00:01<00:00, 13.93batch/s, Train Loss=0.332]\n",
      "Validating: 100%|██████████| 6/6 [00:00<00:00, 20.34batch/s, Validation Loss=0.553]\n",
      "Epoch 10/20: 100%|██████████| 24/24 [00:01<00:00, 14.25batch/s, Train Loss=0.271]\n",
      "Validating: 100%|██████████| 6/6 [00:00<00:00, 22.00batch/s, Validation Loss=0.572]\n",
      "Epoch 11/20: 100%|██████████| 24/24 [00:01<00:00, 13.66batch/s, Train Loss=0.243]\n",
      "Validating: 100%|██████████| 6/6 [00:00<00:00, 20.88batch/s, Validation Loss=0.636]\n",
      "Epoch 12/20: 100%|██████████| 24/24 [00:01<00:00, 13.70batch/s, Train Loss=0.196]\n",
      "Validating: 100%|██████████| 6/6 [00:00<00:00, 20.82batch/s, Validation Loss=0.747]\n",
      "Epoch 13/20: 100%|██████████| 24/24 [00:01<00:00, 13.83batch/s, Train Loss=0.167]\n",
      "Validating: 100%|██████████| 6/6 [00:00<00:00, 20.15batch/s, Validation Loss=0.697]\n",
      "Epoch 14/20: 100%|██████████| 24/24 [00:01<00:00, 14.09batch/s, Train Loss=0.155]\n",
      "Validating: 100%|██████████| 6/6 [00:00<00:00, 21.32batch/s, Validation Loss=0.815]\n",
      "Epoch 15/20: 100%|██████████| 24/24 [00:01<00:00, 13.81batch/s, Train Loss=0.139]\n",
      "Validating: 100%|██████████| 6/6 [00:00<00:00, 21.44batch/s, Validation Loss=0.787]\n",
      "Epoch 16/20: 100%|██████████| 24/24 [00:01<00:00, 14.18batch/s, Train Loss=0.116]\n",
      "Validating: 100%|██████████| 6/6 [00:00<00:00, 21.71batch/s, Validation Loss=0.927]\n",
      "Epoch 17/20: 100%|██████████| 24/24 [00:01<00:00, 14.28batch/s, Train Loss=0.104]\n",
      "Validating: 100%|██████████| 6/6 [00:00<00:00, 20.81batch/s, Validation Loss=0.931]\n",
      "Epoch 18/20: 100%|██████████| 24/24 [00:01<00:00, 14.05batch/s, Train Loss=0.0984]\n",
      "Validating: 100%|██████████| 6/6 [00:00<00:00, 21.53batch/s, Validation Loss=0.957]\n",
      "Epoch 19/20: 100%|██████████| 24/24 [00:01<00:00, 13.81batch/s, Train Loss=0.0959]\n",
      "Validating: 100%|██████████| 6/6 [00:00<00:00, 20.59batch/s, Validation Loss=0.976]\n",
      "Epoch 20/20: 100%|██████████| 24/24 [00:01<00:00, 13.94batch/s, Train Loss=0.0943]\n",
      "Validating: 100%|██████████| 6/6 [00:00<00:00, 21.29batch/s, Validation Loss=0.972]\n"
     ]
    }
   ],
   "source": [
    "# Model parameters\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "embedding_dim = 100\n",
    "hidden_dim = 128\n",
    "output_dim = 1\n",
    "vocab_size = tokenizer.get_vocab_size()\n",
    "\n",
    "# Set up the model, optimizer, and criterion\n",
    "model = BiLSTMClassifier(vocab_size, embedding_dim, hidden_dim, output_dim, pad_token_id).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)  # Set initial LR for the optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Setup OneCycleLR\n",
    "total_steps = len(train_loader) * NUM_EPOCHS # total training steps = num_epochs * batches_per_epoch\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=MAX_LR, total_steps=total_steps)\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, epochs=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82aba4de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T22:02:04.967137Z",
     "iopub.status.busy": "2024-05-30T22:02:04.966130Z",
     "iopub.status.idle": "2024-05-30T22:02:05.261853Z",
     "shell.execute_reply": "2024-05-30T22:02:05.260982Z"
    },
    "papermill": {
     "duration": 0.381593,
     "end_time": "2024-05-30T22:02:05.263978",
     "exception": false,
     "start_time": "2024-05-30T22:02:04.882385",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7492, F1: 0.7084, ROC AUC: 0.8153\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, val_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    with torch.no_grad():\n",
    "        for texts, labels in val_loader:\n",
    "            texts, labels = texts.to(device), labels.to(device).float()\n",
    "            predictions = model(texts).squeeze(1)\n",
    "            probs = torch.sigmoid(predictions)\n",
    "            preds = torch.round(probs)\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    roc_auc = roc_auc_score(all_labels, all_probs)\n",
    "    return accuracy, f1, roc_auc\n",
    "\n",
    "# Example of evaluating the model\n",
    "accuracy, f1, roc_auc = evaluate_model(model, val_loader)\n",
    "print(f'Accuracy: {accuracy:.4f}, F1: {f1:.4f}, ROC AUC: {roc_auc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c225157",
   "metadata": {
    "papermill": {
     "duration": 0.082129,
     "end_time": "2024-05-30T22:02:05.431514",
     "exception": false,
     "start_time": "2024-05-30T22:02:05.349385",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Test predictions and submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0376d47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T22:02:05.640506Z",
     "iopub.status.busy": "2024-05-30T22:02:05.639670Z",
     "iopub.status.idle": "2024-05-30T22:02:05.700224Z",
     "shell.execute_reply": "2024-05-30T22:02:05.699214Z"
    },
    "papermill": {
     "duration": 0.188556,
     "end_time": "2024-05-30T22:02:05.702420",
     "exception": false,
     "start_time": "2024-05-30T22:02:05.513864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer, max_length, pad_token_id):\n",
    "        self.texts = texts\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.pad_token_id = pad_token_id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        tokenized_text = self.tokenizer.encode(text).ids\n",
    "        padded_text = pad_and_truncate(tokenized_text, self.max_length, self.pad_token_id)\n",
    "        return torch.tensor(padded_text)\n",
    "\n",
    "test = pd.read_csv(data_path / 'test.csv')\n",
    "test['text'] = test['text'].apply(preprocess_tweet)\n",
    "\n",
    "# Create the test dataset\n",
    "test_dataset = TestDataset(test['text'].tolist(), tokenizer, MAX_SEQ_LEN, pad_token_id)\n",
    "\n",
    "# Create the test DataLoader\n",
    "test_loader = DataLoader(test_dataset, batch_size=1024, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5063d49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T22:02:05.869627Z",
     "iopub.status.busy": "2024-05-30T22:02:05.869272Z",
     "iopub.status.idle": "2024-05-30T22:02:06.435584Z",
     "shell.execute_reply": "2024-05-30T22:02:06.434646Z"
    },
    "papermill": {
     "duration": 0.651685,
     "end_time": "2024-05-30T22:02:06.437521",
     "exception": false,
     "start_time": "2024-05-30T22:02:05.785836",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  7.17it/s]\n"
     ]
    }
   ],
   "source": [
    "def generate_predictions(model, test_loader):\n",
    "    model.eval()\n",
    "    all_probs = []\n",
    "    with torch.no_grad():\n",
    "        for texts in tqdm(test_loader):\n",
    "            texts = texts.to(device)\n",
    "            predictions = model(texts).squeeze(1)\n",
    "            probs = torch.sigmoid(predictions)\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "    return all_probs\n",
    "\n",
    "# Generate predictions on the test set\n",
    "test_predictions = generate_predictions(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a67d829a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T22:02:06.607185Z",
     "iopub.status.busy": "2024-05-30T22:02:06.606537Z",
     "iopub.status.idle": "2024-05-30T22:02:06.625038Z",
     "shell.execute_reply": "2024-05-30T22:02:06.624211Z"
    },
    "papermill": {
     "duration": 0.105097,
     "end_time": "2024-05-30T22:02:06.626992",
     "exception": false,
     "start_time": "2024-05-30T22:02:06.521895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target\n",
       "0   0       1\n",
       "1   2       1\n",
       "2   3       1\n",
       "3   9       0\n",
       "4  11       1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame({'id':test['id'],'target':test_predictions})\n",
    "submission['target'] = submission['target'].round().astype(int)\n",
    "submission.to_csv('submission.csv',index=False)\n",
    "submission.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2462cfc9",
   "metadata": {
    "papermill": {
     "duration": 0.083194,
     "end_time": "2024-05-30T22:02:06.795416",
     "exception": false,
     "start_time": "2024-05-30T22:02:06.712222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 869809,
     "sourceId": 17777,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 56.956179,
   "end_time": "2024-05-30T22:02:08.400598",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-30T22:01:11.444419",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
