{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/syerramilli/ps3e22-eda-catboost-baseline?scriptVersionId=143811280\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom catboost import CatBoostClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.metrics import f1_score\nfrom scipy.stats import chi2_contingency # for association between different categorical variables\n\nfrom numbers import Number \nfrom pathlib import Path\nfrom typing import Optional, Dict\n\nplt.style.use('ggplot')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-21T23:42:26.939012Z","iopub.execute_input":"2023-09-21T23:42:26.939484Z","iopub.status.idle":"2023-09-21T23:42:28.354465Z","shell.execute_reply.started":"2023-09-21T23:42:26.93944Z","shell.execute_reply":"2023-09-21T23:42:28.353332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = Path('/kaggle/input/playground-series-s3e22')\ntrain = pd.read_csv(path/'train.csv',index_col=['id'])\ntest = pd.read_csv(path/'test.csv',index_col=['id'])\n\ndel train['hospital_number']\ndel test['hospital_number']\n\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-21T23:42:28.356725Z","iopub.execute_input":"2023-09-21T23:42:28.357182Z","iopub.status.idle":"2023-09-21T23:42:28.430801Z","shell.execute_reply.started":"2023-09-21T23:42:28.357152Z","shell.execute_reply":"2023-09-21T23:42:28.429698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Number of rows in training set: {train.shape[0]}')\nprint(f'Number of rows in test set: {test.shape[0]}')","metadata":{"execution":{"iopub.status.busy":"2023-09-21T23:42:28.432081Z","iopub.execute_input":"2023-09-21T23:42:28.432331Z","iopub.status.idle":"2023-09-21T23:42:28.438587Z","shell.execute_reply.started":"2023-09-21T23:42:28.432309Z","shell.execute_reply":"2023-09-21T23:42:28.437435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here's a quick snapshot of the training data. From this snapshot, we can see the following\n1. There are 26 potential feature columns. \n2. There are several numerical features (indicated by dtypes `float64` and `int64` dtypes). None of them have missing entries.\n3. There are several features with dtype - `object`. These are likely categorical valued, although some of them like `age` may be processed as numerical. \n4. Among the columns with the `object` dtype, there are a few entries with missing values.","metadata":{}},{"cell_type":"code","source":"# quick snapshot\ntrain.info()","metadata":{"execution":{"iopub.status.busy":"2023-09-21T23:42:28.439831Z","iopub.execute_input":"2023-09-21T23:42:28.440145Z","iopub.status.idle":"2023-09-21T23:42:28.466033Z","shell.execute_reply.started":"2023-09-21T23:42:28.440122Z","shell.execute_reply":"2023-09-21T23:42:28.464518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Target\n\nThe goal of this task to predict `outcome` - whether the horse survived or not - based on past medical conditions. There are three classes: lived, died, and euthanized. In the cell below, we show the bar plot of the counts for each class. ","metadata":{}},{"cell_type":"code","source":"train['outcome'].value_counts().plot(kind='barh')","metadata":{"execution":{"iopub.status.busy":"2023-09-21T23:42:28.468952Z","iopub.execute_input":"2023-09-21T23:42:28.469324Z","iopub.status.idle":"2023-09-21T23:42:28.718694Z","shell.execute_reply.started":"2023-09-21T23:42:28.469289Z","shell.execute_reply":"2023-09-21T23:42:28.717527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Lesions \n\nFrom the description in the [original dataset](https://www.kaggle.com/datasets/yasserh/horse-survival-dataset), the columns `lesion_1`, `lesion_2` and `lesion_3` encode the site, type, subtype, and specific code.","metadata":{}},{"cell_type":"code","source":"for i in range(1,4):\n    column = f'lesion_{i}'\n    print(f\"Number of unique values in {column}: {train[column].nunique()}\")","metadata":{"execution":{"iopub.status.busy":"2023-09-21T23:42:28.72042Z","iopub.execute_input":"2023-09-21T23:42:28.720778Z","iopub.status.idle":"2023-09-21T23:42:28.727584Z","shell.execute_reply.started":"2023-09-21T23:42:28.720747Z","shell.execute_reply":"2023-09-21T23:42:28.726087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It turns out almost all the entires of `lesion_2` and `lesion_3` are 0. Therefore, we will drop them in the remaining analysis.","metadata":{}},{"cell_type":"code","source":"for i in range(2,4):\n    print(train[f'lesion_{i}'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2023-09-21T23:42:28.729524Z","iopub.execute_input":"2023-09-21T23:42:28.730123Z","iopub.status.idle":"2023-09-21T23:42:28.744073Z","shell.execute_reply.started":"2023-09-21T23:42:28.73009Z","shell.execute_reply":"2023-09-21T23:42:28.743019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dropping lesion_2 and lesion_3\ntrain = train.drop(['lesion_2','lesion_3'],axis=1)\ntest = test.drop(['lesion_2','lesion_3'],axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T23:42:28.745221Z","iopub.execute_input":"2023-09-21T23:42:28.745517Z","iopub.status.idle":"2023-09-21T23:42:28.758143Z","shell.execute_reply.started":"2023-09-21T23:42:28.745487Z","shell.execute_reply":"2023-09-21T23:42:28.75729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Lesion site","metadata":{}},{"cell_type":"code","source":"def map_lesion_site(value:str) -> str:\n    if value[:2] == \"11\" and len(value) == 5:\n        return \"all_intestinal\"\n    elif value[0] == \"1\":\n        return \"gastric\"\n    elif value[0] == \"2\":\n        return \"sm_intestine\"\n    elif value[0] == \"3\":\n        return \"lg_colon\"\n    elif value[0] == \"4\":\n        return \"lg_colon_and_cecum\"\n    elif value[0] == \"5\":\n        return \"cecum\"\n    elif value[0] == \"6\":\n        return \"transverse_colon\"\n    elif value[0] == \"7\":\n        return \"retum_colon\"\n    elif value[0] == \"8\":\n        return \"uterus\"\n    elif value[0] == \"9\":\n        return \"bladder\"\n    elif value[0] == \"0\":\n        return \"none\"\n    else:\n        return \"ERROR\"\n    \ntrain['lesion_site'] = train['lesion_1'].astype(str).apply(map_lesion_site)\ntest['lesion_site'] = test['lesion_1'].astype(str).apply(map_lesion_site)\n\nfig,ax = plt.subplots(1, 1, figsize=(6,4))\ntrain['lesion_site'].value_counts().plot(kind='bar', ax=ax)\n_ = ax.tick_params(axis='x', rotation=60)\n# to be used later\nsite_order = [text.get_text() for text in ax.get_xticklabels()]","metadata":{"execution":{"iopub.status.busy":"2023-09-21T23:42:28.759213Z","iopub.execute_input":"2023-09-21T23:42:28.759714Z","iopub.status.idle":"2023-09-21T23:42:29.011192Z","shell.execute_reply.started":"2023-09-21T23:42:28.759686Z","shell.execute_reply":"2023-09-21T23:42:29.009924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ax = (\n    train\n    .groupby('lesion_site')['outcome']\n    .value_counts(normalize=True)\n    .mul(100)\n    .rename('Percentage')\n    .reset_index()\n    .pipe(\n        (sns.catplot,'data'), y='lesion_site',x='Percentage',hue='outcome',\n        order= site_order,\n        hue_order=['died', 'euthanized', 'lived'],\n        kind='bar', height=5, aspect=7/5\n    )\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T23:42:29.012831Z","iopub.execute_input":"2023-09-21T23:42:29.01342Z","iopub.status.idle":"2023-09-21T23:42:29.511654Z","shell.execute_reply.started":"2023-09-21T23:42:29.01339Z","shell.execute_reply":"2023-09-21T23:42:29.510597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Lesion type\n","metadata":{}},{"cell_type":"code","source":"def map_lesion_type(value:str) -> str:\n    if value == '0':\n        return \"none\"\n    \n    value2 = value[2] if len(value)==5 else value[1]\n    \n    if value2 == '1':\n        return \"simple\"\n    elif value2 == '2':\n        return 'strangulation'\n    elif value2 == '3':\n        return 'inflammation'\n    elif value2 == '4':\n        return 'other'\n    \n    return 'ERROR'\n\ntrain['lesion_type'] = train['lesion_1'].astype(str).apply(map_lesion_type)\ntest['lesion_type'] = test['lesion_1'].astype(str).apply(map_lesion_type)\n\nfig,ax = plt.subplots(1, 1, figsize=(6,4))\ntrain['lesion_type'].value_counts().plot(kind='bar', ax=ax)\n_ = ax.tick_params(axis='x', rotation=60)\n# to be used later\ntype_order = [text.get_text() for text in ax.get_xticklabels()]","metadata":{"execution":{"iopub.status.busy":"2023-09-21T23:42:29.512823Z","iopub.execute_input":"2023-09-21T23:42:29.513057Z","iopub.status.idle":"2023-09-21T23:42:29.703158Z","shell.execute_reply.started":"2023-09-21T23:42:29.513035Z","shell.execute_reply":"2023-09-21T23:42:29.702012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ax = (\n    train\n    .groupby('lesion_type')['outcome']\n    .value_counts(normalize=True)\n    .mul(100)\n    .rename('Percentage')\n    .reset_index()\n    .pipe(\n        (sns.catplot,'data'), y='lesion_type',x='Percentage',hue='outcome',\n        order= type_order,\n        hue_order=['died', 'euthanized', 'lived'],\n        kind='bar', height=4, aspect=6/4\n    )\n)\n#_ = ax.tick_params(axis='x', rotation=30)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T23:42:29.704575Z","iopub.execute_input":"2023-09-21T23:42:29.705057Z","iopub.status.idle":"2023-09-21T23:42:30.096691Z","shell.execute_reply.started":"2023-09-21T23:42:29.705032Z","shell.execute_reply":"2023-09-21T23:42:30.095749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**TODO**: Decode the lesion subtype and code. ","metadata":{}},{"cell_type":"code","source":"# delete lesion_1\ndel train['lesion_1']\ndel test['lesion_1']","metadata":{"execution":{"iopub.status.busy":"2023-09-21T23:42:30.098107Z","iopub.execute_input":"2023-09-21T23:42:30.099789Z","iopub.status.idle":"2023-09-21T23:42:30.105216Z","shell.execute_reply.started":"2023-09-21T23:42:30.099756Z","shell.execute_reply":"2023-09-21T23:42:30.104154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Numerical Features","metadata":{}},{"cell_type":"code","source":"numerical_cols= train.select_dtypes(include=['number']).columns.tolist()\nprint(f'Number of numerical columns: {len(numerical_cols)}')","metadata":{"execution":{"iopub.status.busy":"2023-09-21T23:42:30.109335Z","iopub.execute_input":"2023-09-21T23:42:30.109623Z","iopub.status.idle":"2023-09-21T23:42:30.121377Z","shell.execute_reply.started":"2023-09-21T23:42:30.1096Z","shell.execute_reply":"2023-09-21T23:42:30.120308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We plot the histograms of the 10 numerical features in the cell below.  The features `respiratory_rate`, `total_protein`, and `abdomo_protein`  have positive skew.","metadata":{}},{"cell_type":"code","source":"n_rows = 2\nn_cols = 4\nfig,axs = plt.subplots(n_rows,n_cols,figsize=(4*n_cols,3*n_rows))\nfor i in range(n_rows):\n    for j in range(n_cols):\n        col_index = n_cols*i+j\n        if col_index == 7:\n            break\n        _ = sns.histplot(data=train,x=numerical_cols[col_index], ax=axs[i,j],bins=20)\n        \nfig.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2023-09-21T23:42:30.122621Z","iopub.execute_input":"2023-09-21T23:42:30.123037Z","iopub.status.idle":"2023-09-21T23:42:31.822701Z","shell.execute_reply.started":"2023-09-21T23:42:30.123004Z","shell.execute_reply":"2023-09-21T23:42:31.821525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To confirm our observations about the skew in the distributions in some of the features, we compute the skewness statistic for the remaining 8 numerical features.","metadata":{}},{"cell_type":"code","source":"skewness = train[numerical_cols].skew().sort_values(ascending=False)\nskewness","metadata":{"execution":{"iopub.status.busy":"2023-09-21T23:42:31.823916Z","iopub.execute_input":"2023-09-21T23:42:31.824206Z","iopub.status.idle":"2023-09-21T23:42:31.836643Z","shell.execute_reply.started":"2023-09-21T23:42:31.824183Z","shell.execute_reply":"2023-09-21T23:42:31.835603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We now plot the boxplots of the features grouped by the different classes. For the 4 features with significant positive skew, we apply a log transform before generating the boxplot. Some observations:\n\n1. The horses that lived generally had a lower `pulse`  than the other groups.\n2. They also had a lower `packed_cell_volume` than the other groups\n3. Horses that were euthanized had orders of magnitude higher `total_protein` than the other two groups, although there are quite a few outliers in the other groups.","metadata":{}},{"cell_type":"code","source":"n_rows = 2\nn_cols = 4\nfig,axs = plt.subplots(n_rows,n_cols,figsize=(3*n_cols,3*n_rows))\nfor i in range(n_rows):\n    for j in range(n_cols):\n        col_index = n_cols*i+j\n        if col_index == 7:\n            break\n        \n        \n        column = numerical_cols[col_index]\n        \n        if skewness.loc[column] > 1:\n            _ = sns.boxplot(y=np.log(train[column]),x=train['outcome'],ax=axs[i,j])\n            _ = axs[i,j].set_ylabel(f'log({column})')\n        else:\n            _ = sns.boxplot(data=train,y=column,x='outcome', ax=axs[i,j])\n        \nfig.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2023-09-21T23:42:31.838023Z","iopub.execute_input":"2023-09-21T23:42:31.838737Z","iopub.status.idle":"2023-09-21T23:42:33.01929Z","shell.execute_reply.started":"2023-09-21T23:42:31.838704Z","shell.execute_reply":"2023-09-21T23:42:33.018608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here is the histogram plot of the features grouped by outcome. For the 4 features with significant positive skew, we apply a log transform before generating the boxplot. Some observations:","metadata":{}},{"cell_type":"code","source":"n_rows = 2\nn_cols = 4\nfig,axs = plt.subplots(n_rows,n_cols,figsize=(5*n_cols,3*n_rows))\nfor i in range(n_rows):\n    for j in range(n_cols):\n        col_index = n_cols*i+j\n        if col_index == 7:\n            break\n        \n        \n        column = numerical_cols[col_index]\n        \n        if skewness.loc[column] > 1:\n            _ = sns.histplot(x=np.log(train[column]), hue=train['outcome'],ax=axs[i,j], bins=20, stat='density', kde=True)\n            _ = axs[i,j].set_xlabel(f'log({column})')\n        else:\n            _ = sns.histplot(data=train,x=column,hue='outcome', ax=axs[i,j], bins=20, stat='density', kde=True)\n            \n        if col_index > 0:\n            _ = axs[i,j].get_legend().remove()\n        \nfig.tight_layout()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-21T23:42:33.020342Z","iopub.execute_input":"2023-09-21T23:42:33.0214Z","iopub.status.idle":"2023-09-21T23:42:35.60259Z","shell.execute_reply.started":"2023-09-21T23:42:33.021354Z","shell.execute_reply":"2023-09-21T23:42:35.59963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Finally, we plot the correlation heatmap, where we compute the Spearman rank correlation. There are no red flags here.","metadata":{}},{"cell_type":"code","source":"corr_matrix = train[numerical_cols].corr(method='spearman')\nmask =np.triu(np.ones_like(corr_matrix, dtype=bool))\nfig,ax = plt.subplots(1,1,figsize=(5,4),dpi=150)\n_ = sns.heatmap(corr_matrix,annot=True,fmt='.2f',mask=mask,ax=ax)\n_ = ax.set_facecolor('w')\n","metadata":{"execution":{"iopub.status.busy":"2023-09-21T23:42:35.60397Z","iopub.execute_input":"2023-09-21T23:42:35.604286Z","iopub.status.idle":"2023-09-21T23:42:35.940528Z","shell.execute_reply.started":"2023-09-21T23:42:35.604261Z","shell.execute_reply":"2023-09-21T23:42:35.939605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Numerical feature engineering","metadata":{}},{"cell_type":"code","source":"train['log_pulseSq_total_protein'] = -np.log(train['total_protein']) + 2*np.log(train['pulse'])\ntest['log_pulseSq_total_protein'] = -np.log(test['total_protein']) + 2*np.log(test['pulse'])\n\n\n_ = sns.histplot(data=train, x='log_pulseSq_total_protein',hue='outcome', kde=True, stat='density')","metadata":{"execution":{"iopub.status.busy":"2023-09-21T23:42:35.941946Z","iopub.execute_input":"2023-09-21T23:42:35.942229Z","iopub.status.idle":"2023-09-21T23:42:36.355491Z","shell.execute_reply.started":"2023-09-21T23:42:35.942204Z","shell.execute_reply":"2023-09-21T23:42:36.354412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Categorical features","metadata":{}},{"cell_type":"code","source":"rem_columns = train.drop('outcome',axis=1).select_dtypes(include=['object']).columns.tolist()\nprint(f'Number of columns with dtype object: {len(rem_columns)}')","metadata":{"execution":{"iopub.status.busy":"2023-09-21T23:42:36.356532Z","iopub.execute_input":"2023-09-21T23:42:36.356792Z","iopub.status.idle":"2023-09-21T23:42:36.366886Z","shell.execute_reply.started":"2023-09-21T23:42:36.356771Z","shell.execute_reply":"2023-09-21T23:42:36.365455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will exlcude any column where the mode (aka most common value) occurs in more than 85% of the entries.","metadata":{}},{"cell_type":"code","source":"def get_mode_fraction(x:pd.Series) -> float:\n    cts = x.value_counts(sort=True, ascending=False)\n    return cts.iloc[0]/x.shape[0]\n\nfor i, column in enumerate(rem_columns):\n    mode_frac = get_mode_fraction(train[column])\n    if mode_frac > 0.85:\n        # drop the feature if >85% of the observations \n        # belong to the mode\n        print(f'Dropping {column} with the mode having {mode_frac*100:.2f}% observations')\n        \n        del train[column]\n        del test[column]\n        \n        rem_columns.pop(i)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T23:42:36.368322Z","iopub.execute_input":"2023-09-21T23:42:36.368696Z","iopub.status.idle":"2023-09-21T23:42:36.388232Z","shell.execute_reply.started":"2023-09-21T23:42:36.368671Z","shell.execute_reply":"2023-09-21T23:42:36.386999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We now run chi-squared contigency tests to test the significance of the relationships of each categorical feature with the response. It appears that all 16 features have significant relationship with `outcome`.","metadata":{}},{"cell_type":"code","source":"def contingency_test(input_col:str, significance_level:float=0.01) -> bool:\n    stat,pval,_,_ = chi2_contingency(pd.crosstab(train[input_col], train['outcome']))\n    \n    return abs(stat), pval < significance_level\n\nchi2_tests_df = pd.DataFrame(\n    [contingency_test(column) for column in rem_columns],\n    index=rem_columns,\n    columns=['abs_stat', 'is_significant']\n).sort_values(by=['is_significant', 'abs_stat'], ascending=False)\n\nprint(f'Number of categorical features with signficant relationship with outcome: {chi2_tests_df[\"is_significant\"].sum()}')","metadata":{"execution":{"iopub.status.busy":"2023-09-21T23:42:36.389331Z","iopub.execute_input":"2023-09-21T23:42:36.389717Z","iopub.status.idle":"2023-09-21T23:42:36.512819Z","shell.execute_reply.started":"2023-09-21T23:42:36.389692Z","shell.execute_reply":"2023-09-21T23:42:36.512125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In the cell below, we generate a bar plots of the counts of the categories for each of these features, *except the two lesion features decoded earlier*. Within each category, we separate the counts by class. Some preliminary observations:\n\n1. For all the features, the class counts seem to differ between atleast two categories, suggesting some relationship.\n2. Some of the features like `temp_of_extremities`can be encoded as ordinal integers. This can help reduce the dimensionaloity.\n3. For a lot of features, some of the categories have very few observations. We might need to merge these categories to learn something useful. ","metadata":{}},{"cell_type":"code","source":"n_rows = 5\nn_cols = 3\nfig,axs = plt.subplots(n_rows,n_cols,figsize=(5*n_cols,4*n_rows))\nfor i in range(n_rows):\n    for j in range(n_cols):\n        column = rem_columns[n_cols*i+j]\n        _ = sns.countplot(data=train,x=column,hue='outcome', ax=axs[i,j])\n        _ = axs[i,j].tick_params(axis='x', rotation=30)\n        \nfig.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2023-09-21T23:42:36.513711Z","iopub.execute_input":"2023-09-21T23:42:36.514115Z","iopub.status.idle":"2023-09-21T23:42:39.682911Z","shell.execute_reply.started":"2023-09-21T23:42:36.51409Z","shell.execute_reply":"2023-09-21T23:42:39.681972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**TODO**: Merge categories of the `lesion_site` feature so that the model can learn something useful for categories with very few observations.","metadata":{}},{"cell_type":"code","source":"categorical_columns = [\n    'mucous_membrane', 'abdomen','rectal_exam_feces', \n    'lesion_site', 'lesion_type' \n]\n\ndef preprocess_categorical(df:pd.DataFrame) -> None:\n    # cleaning some of the categorical features\n    df['peristalsis'] = df['peristalsis'].replace('distend_small',pd.NA)\n    df['rectal_exam_feces'] = df['rectal_exam_feces'].replace('serosanguious',pd.NA)\n    \n    # merging some of the categories\n    df['capillary_refill_time'] = df['capillary_refill_time'].replace('3','more_3_sec')\n    df['pain'] = df['pain'].replace('slight','alert')\n    \n    \n    # encoding some of the catgeorical level \n    ordinal_and_binary_dict = {\n        'surgery': ['no','yes'], \n        'temp_of_extremities': ['cold','cool', 'normal', 'warm'], \n        'peripheral_pulse': ['absent','reduced', 'normal','increased'], \n        'pain':['alert', 'depressed', 'mild_pain', 'moderate', 'severe_pain', 'extreme_pain'],\n        'capillary_refill_time': ['less_3_sec', 'more_3_sec'], \n        'peristalsis': ['absent', 'hypomotile', 'normal', 'hypermotile'], \n        'abdominal_distention': ['none', 'slight', 'moderate', 'severe'], \n        'nasogastric_tube': ['none', 'slight', 'significant'], \n        'nasogastric_reflux': ['none','slight','less_1_liter', 'more_1_liter'], \n        'abdomo_appearance': ['serosanguious', 'cloudy', 'clear'], \n        'surgical_lesion': ['no', 'yes'], \n        'cp_data': ['no', 'yes']\n    }\n    \n    for column, levels in ordinal_and_binary_dict.items():\n        df[column] = df[column].replace({\n            level:i for i,level in enumerate(levels)\n        })\n        \n    for column in categorical_columns:\n        # useful for other featur\n        df[column] = df[column].astype('category')\n        \n\n# modify columns in place\npreprocess_categorical(train)\npreprocess_categorical(test)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T23:42:39.684123Z","iopub.execute_input":"2023-09-21T23:42:39.684925Z","iopub.status.idle":"2023-09-21T23:42:39.724464Z","shell.execute_reply.started":"2023-09-21T23:42:39.684893Z","shell.execute_reply":"2023-09-21T23:42:39.723819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Missing values\n\nIn the quick snapshot earlier, we found that some of the features (encoded as `object`) have some values missing. In the cell below, I compute the fraction of missing values in each column. (Note: Columns with no missing values are excluded).","metadata":{}},{"cell_type":"code","source":"def filter_greater_than(series:pd.Series,threshold:Number) -> pd.Series:\n    '''\n    Returns series elements greater than threshold. This funtion can be\n    used with the .pipe methods\n    '''\n    return series[series>threshold]\n\ndef get_perc_missing(df:pd.DataFrame) -> pd.Series:\n    return (\n        (df.isnull().sum()/df.shape[0]*100)\n        .sort_values(ascending=False)\n        .pipe(filter_greater_than,threshold=0)\n        .round(3)\n    )\n\nperc_missing = get_perc_missing(train)\nperc_missing","metadata":{"execution":{"iopub.status.busy":"2023-09-21T23:42:39.725724Z","iopub.execute_input":"2023-09-21T23:42:39.726745Z","iopub.status.idle":"2023-09-21T23:42:39.739425Z","shell.execute_reply.started":"2023-09-21T23:42:39.726713Z","shell.execute_reply":"2023-09-21T23:42:39.738258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The same columns have missing entries in the test set too, and the percentage of missing values in the test set is roughly the same. So, we will need a concrete imputation strategy.","metadata":{}},{"cell_type":"code","source":"perc_missing_test = get_perc_missing(test)\nassert perc_missing.shape[0] == perc_missing_test.shape[0]\nperc_missing_test","metadata":{"execution":{"iopub.status.busy":"2023-09-21T23:42:39.741007Z","iopub.execute_input":"2023-09-21T23:42:39.741313Z","iopub.status.idle":"2023-09-21T23:42:39.764637Z","shell.execute_reply.started":"2023-09-21T23:42:39.741286Z","shell.execute_reply":"2023-09-21T23:42:39.762739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For `abdomen` and `rectal_exam_feces`, we add a new category called `\"missing\"` for the missing entries.","metadata":{}},{"cell_type":"code","source":"for column in ['abdomen','rectal_exam_feces']:\n    train[column] = train[column].astype('object').fillna('missing').astype('category')\n    test[column] = test[column].astype('object').fillna('missing').astype('category')","metadata":{"execution":{"iopub.status.busy":"2023-09-21T23:42:39.766285Z","iopub.execute_input":"2023-09-21T23:42:39.76664Z","iopub.status.idle":"2023-09-21T23:42:39.783431Z","shell.execute_reply.started":"2023-09-21T23:42:39.766611Z","shell.execute_reply":"2023-09-21T23:42:39.782321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For the remaining columns, we impute the missing value with the mode. \n\nTODO: Use a more systematic imputation strategy.","metadata":{}},{"cell_type":"code","source":"for column in perc_missing.iloc[2:].index:\n    mode_col = train[column].mode().iloc[0]\n    train[column] = train[column].fillna(mode_col)\n    test[column] = test[column].fillna(mode_col)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T23:42:39.785101Z","iopub.execute_input":"2023-09-21T23:42:39.785355Z","iopub.status.idle":"2023-09-21T23:42:39.802096Z","shell.execute_reply.started":"2023-09-21T23:42:39.785331Z","shell.execute_reply":"2023-09-21T23:42:39.801088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Catboost model\n\nThe function `fit_model` in the cell below, trains a catboost classification model that uses bagging for the individual trees. The function also allows the specification of hyperparameters as a dictionary through the `config` argument. If `config` is not specified, default values for the hyperparameters are used.","metadata":{}},{"cell_type":"code","source":"def fit_model(\n    X:pd.DataFrame,\n    y:np.ndarray,\n    config:Optional[Dict]=None,\n    n_jobs:int=1,\n    verbose:int=0,\n    random_seed:int=100,\n) -> CatBoostClassifier:\n    '''\n    Train a catboost classifier\n    '''\n    model = CatBoostClassifier(\n        iterations = 500,\n        thread_count = n_jobs,\n        bootstrap_type = 'Bernoulli',\n        subsample = 0.8,\n        random_seed = random_seed,\n        verbose = verbose\n    )\n    \n    if config:\n        # if config is supplied, set the model hyperparameters\n        model.set_params(**config)\n        \n    cat_features = [\n        column for column in X.columns if X[column].dtype == 'category'\n    ]\n        \n    return model.fit(X, y, cat_features= cat_features)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-21T23:55:33.36343Z","iopub.execute_input":"2023-09-21T23:55:33.364304Z","iopub.status.idle":"2023-09-21T23:55:33.372654Z","shell.execute_reply.started":"2023-09-21T23:55:33.364268Z","shell.execute_reply":"2023-09-21T23:55:33.371647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train.drop('outcome',axis=1)\nle = LabelEncoder()\ny = le.fit_transform(train['outcome'].values)\n\nmodel = fit_model(X, y, n_jobs=4, verbose=50, random_seed=100)\nmodel.save_model('baseline.cbm',format='cbm')","metadata":{"execution":{"iopub.status.busy":"2023-09-21T23:47:03.672269Z","iopub.execute_input":"2023-09-21T23:47:03.673129Z","iopub.status.idle":"2023-09-21T23:47:07.427739Z","shell.execute_reply.started":"2023-09-21T23:47:03.6731Z","shell.execute_reply":"2023-09-21T23:47:07.426403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Cross-validation\n\nTo provide a numerical measure for the baseline, we will use the f1score estimate from 4 replicates of 10-fold stratified cross-validation. We use replicated CV here since the size of the training set is small.","metadata":{}},{"cell_type":"code","source":"import warnings\nfrom tqdm import tqdm\ndef fit_and_test_fold(X, y, train_index,test_index) -> float:\n    X_train = X.iloc[train_index,:];X_test = X.iloc[test_index,:]\n    y_train = y[train_index]; y_test = y[test_index]\n    \n    # fit model on training data\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\")\n        model = fit_model(X_train, y_train, n_jobs=4)\n    \n    # generate predictions on test data\n    test_pred = model.predict(X_test)\n    \n    return f1_score(y_test, test_pred, average='micro')\n\n\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=4, random_state=1)\ncv_f1_scores = [None]*40\nfor i, (train_index, test_index) in tqdm(enumerate(cv.split(X,y))):\n    cv_f1_scores[i] = fit_and_test_fold(X, y, train_index, test_index)\n\ncv_f1 = np.mean(cv_f1_scores)\nprint(f'CV F1 for baseline model: {cv_f1:.3f}')","metadata":{"execution":{"iopub.status.busy":"2023-09-21T23:47:14.667044Z","iopub.execute_input":"2023-09-21T23:47:14.66742Z","iopub.status.idle":"2023-09-21T23:49:33.756856Z","shell.execute_reply.started":"2023-09-21T23:47:14.667394Z","shell.execute_reply":"2023-09-21T23:49:33.755577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CV F1 for each replicate of 10-fold CV\n# Clearly, there is some variability across replicates\nnp.array(cv_f1_scores).reshape(-1,10).mean(-1)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T23:49:33.758462Z","iopub.execute_input":"2023-09-21T23:49:33.758817Z","iopub.status.idle":"2023-09-21T23:49:33.767598Z","shell.execute_reply.started":"2023-09-21T23:49:33.758787Z","shell.execute_reply":"2023-09-21T23:49:33.766418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Feature importances\n\n\n\nWe now compute the gain based feature importance measures from the catboost model.\n\n**Notes**:\n1. Feature importance measures from tree based models can be misleading.\n2. In catboost, the default feature importance measure is based on the total gain from splits involving the feature.","metadata":{}},{"cell_type":"code","source":"# gain based feature importances - not necessarily the most reliable\nfeat_imp = pd.Series(model.feature_importances_,X.columns).sort_values(ascending=True)\nfeat_imp.plot(kind='barh')","metadata":{"execution":{"iopub.status.busy":"2023-09-21T23:49:51.447331Z","iopub.execute_input":"2023-09-21T23:49:51.447669Z","iopub.status.idle":"2023-09-21T23:49:51.769359Z","shell.execute_reply.started":"2023-09-21T23:49:51.447642Z","shell.execute_reply":"2023-09-21T23:49:51.768337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature importances through SHAP\n\nThe default feature importances computed by catboost (or any tree based model) can be misleading. Here, we will use SHAP measures to check the importance of each feature.\n\nSHAP values represent the impact of each feature on the model's output for a specific instance. In multiclass classification, we will have a **separate** set of SHAP values for each class. These values tell us how each feature contributes to each class prediction, i.e., distinguishing the specific class from the rest.","metadata":{}},{"cell_type":"code","source":"import shap\n\nexplainer = shap.TreeExplainer(model)\nshap_values = explainer.shap_values(X)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T23:49:55.183421Z","iopub.execute_input":"2023-09-21T23:49:55.184578Z","iopub.status.idle":"2023-09-21T23:49:55.82472Z","shell.execute_reply.started":"2023-09-21T23:49:55.18451Z","shell.execute_reply":"2023-09-21T23:49:55.823777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In the SHAP summary plot, we plot a horizontal bar plot of the absolute SHAP value for each feature averaged across the observations.\nFeatures with longer bars have a higher influence on the model's output for the specific class. Since we have 3 classes here, we will see 3 stacked bars for each feature. The features are ordered according to the cumulative length of the 3 bars. \n\nLet's look at the top 3 features from the plot below. \n\n1. `lesion_type` is very important for predicting \"lived\" outcomes,  and moderately important for predicting \"died\" outcomes and \"euthanized\" outcomes.\n2. `total_protein` is very important for predicting \"died\" and \"euthanized\" outcomes, but not important for predicting \"lived\" outcomes.\n3. `pain` is important for predicting \"lived\" and \"died\" outcomes, but not important for predicting \"euthanized\" outcomes.","metadata":{}},{"cell_type":"code","source":"# Average of SHAP value magnitudes across the dataset\nshap.summary_plot(\n    shap_values, X, plot_type=\"bar\",\n    class_names = le.classes_,\n    plot_size = (10,6)\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T23:50:10.894123Z","iopub.execute_input":"2023-09-21T23:50:10.894492Z","iopub.status.idle":"2023-09-21T23:50:11.351626Z","shell.execute_reply.started":"2023-09-21T23:50:10.894462Z","shell.execute_reply":"2023-09-21T23:50:11.350635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In the cell below, we show the SHAP values separately by class. We only show the top 10 features.","metadata":{}},{"cell_type":"code","source":"avg_shap_class = [\n    pd.Series(\n        np.abs(shap_values[i]).mean(0),\n        index = X.columns.tolist()\n    ).sort_values(ascending=True) for i in range(3)\n]\n\nfig, axs = plt.subplots(1, 3, figsize=(15,4), dpi=150)\nfor i in range(3):\n    _ = avg_shap_class[i].iloc[-10:].plot(kind='barh', ax=axs[i])\n    _ = axs[i].set_title(f'Class: {le.classes_[i]}')\n    \nfig.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2023-09-21T23:50:59.015952Z","iopub.execute_input":"2023-09-21T23:50:59.016284Z","iopub.status.idle":"2023-09-21T23:50:59.747866Z","shell.execute_reply.started":"2023-09-21T23:50:59.016258Z","shell.execute_reply":"2023-09-21T23:50:59.746638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dependence plots\n\nIn the cell below, we plot the SHAP dependence plots for the top 3 features for each class. ","metadata":{}},{"cell_type":"code","source":"n_features = 3\nfor i in range(3):\n    fig, axs = plt.subplots(1, n_features, figsize=(5*n_features,4), dpi=100)\n    \n    features = avg_shap_class[i].iloc[-n_features:].iloc[::-1].index.tolist()\n    \n    for j, feature in enumerate(features):\n        _ = shap.dependence_plot(\n            feature, shap_values[i], X, \n            interaction_index= None, alpha=0.7,\n            ax = axs[j], show=False\n        )\n        if X[feature].dtype == 'category':\n            _ = axs[j].tick_params(axis='x', rotation=60)\n        \n    fig.suptitle(f'SHAP dependence plots for class={le.classes_[i]}')\n    fig.tight_layout(rect=[0,0,1,0.99])\n    fig.savefig(f'SHAP_dependence_{le.classes_[i]}',bbox_inches='tight')\n    fig.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-21T23:51:08.667523Z","iopub.execute_input":"2023-09-21T23:51:08.66879Z","iopub.status.idle":"2023-09-21T23:51:11.331937Z","shell.execute_reply.started":"2023-09-21T23:51:08.668753Z","shell.execute_reply":"2023-09-21T23:51:11.330942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model with fewer features\n\nWe will now consider a model with the reduced number of features. The selected features occur in the set of top 10 features for atleast one of the three classes.","metadata":{}},{"cell_type":"code","source":"reduced_features = set()\nfor i in range(3):\n    reduced_features = reduced_features.union(\n        set(avg_shap_class[i].iloc[-10:].index.tolist())\n    )\n    \nreduced_features = list(reduced_features)\nprint(f'Number of feature selected: {len(reduced_features)}')\nprint('List of selected features:')\nprint(reduced_features)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T23:54:13.906192Z","iopub.execute_input":"2023-09-21T23:54:13.906524Z","iopub.status.idle":"2023-09-21T23:54:13.913034Z","shell.execute_reply.started":"2023-09-21T23:54:13.906498Z","shell.execute_reply":"2023-09-21T23:54:13.912059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=4, random_state=1)\ncv_f1_reduced_scores = [None]*40\nfor i, (train_index, test_index) in tqdm(enumerate(cv.split(X,y))):\n    cv_f1_reduced_scores[i] = fit_and_test_fold(X[reduced_features], y, train_index, test_index)\n\ncv_f1_reduced = np.mean(cv_f1_reduced_scores)\nprint(f'CV F1 for model with reduced number of features: {cv_f1_reduced:.3f}')","metadata":{"execution":{"iopub.status.busy":"2023-09-21T23:57:07.582234Z","iopub.execute_input":"2023-09-21T23:57:07.582604Z","iopub.status.idle":"2023-09-21T23:59:02.636688Z","shell.execute_reply.started":"2023-09-21T23:57:07.582573Z","shell.execute_reply":"2023-09-21T23:59:02.635505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CV F1 for each replicate of 10-fold CV\n# Clearly, there is some variability across replicates\nnp.array(cv_f1_reduced_scores).reshape(-1,10).mean(-1)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T23:59:02.638874Z","iopub.execute_input":"2023-09-21T23:59:02.63923Z","iopub.status.idle":"2023-09-21T23:59:02.646639Z","shell.execute_reply.started":"2023-09-21T23:59:02.6392Z","shell.execute_reply":"2023-09-21T23:59:02.64544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_reduced = fit_model(X[reduced_features], y, n_jobs=4, verbose=50, random_seed=12)\n# save models to disk\nmodel_reduced.save_model('reduced_feats.cbm',format='cbm')","metadata":{"execution":{"iopub.status.busy":"2023-09-21T23:59:02.647908Z","iopub.execute_input":"2023-09-21T23:59:02.648177Z","iopub.status.idle":"2023-09-21T23:59:05.685292Z","shell.execute_reply.started":"2023-09-21T23:59:02.64815Z","shell.execute_reply":"2023-09-21T23:59:05.68369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Test predictions","metadata":{}},{"cell_type":"code","source":"submission = pd.DataFrame({\n    'id':test.index.values,\n    'outcome':le.inverse_transform(model.predict(test).ravel())\n})\nsubmission.to_csv('submission_orig.csv',index=False)\nsubmission['outcome'].value_counts()/submission.shape[0]","metadata":{"execution":{"iopub.status.busy":"2023-09-21T23:59:14.939484Z","iopub.execute_input":"2023-09-21T23:59:14.939859Z","iopub.status.idle":"2023-09-21T23:59:14.959408Z","shell.execute_reply.started":"2023-09-21T23:59:14.939828Z","shell.execute_reply":"2023-09-21T23:59:14.958594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({\n    'id':test.index.values,\n    'outcome':le.inverse_transform(model_reduced.predict(test[reduced_features]).ravel())\n})\nsubmission.to_csv('submission_reduced.csv',index=False)\nsubmission['outcome'].value_counts()/submission.shape[0]","metadata":{"execution":{"iopub.status.busy":"2023-09-21T23:59:16.495104Z","iopub.execute_input":"2023-09-21T23:59:16.495485Z","iopub.status.idle":"2023-09-21T23:59:16.51452Z","shell.execute_reply.started":"2023-09-21T23:59:16.495457Z","shell.execute_reply":"2023-09-21T23:59:16.513272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}