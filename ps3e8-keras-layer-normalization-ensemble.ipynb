{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe89f5a4",
   "metadata": {
    "_execution_state": "idle",
    "_uuid": "051d70d956493feee0c6d64651c6a088724dca2a",
    "execution": {
     "iopub.execute_input": "2023-03-04T17:49:06.823233Z",
     "iopub.status.busy": "2023-03-04T17:49:06.822514Z",
     "iopub.status.idle": "2023-03-04T17:49:07.613585Z",
     "shell.execute_reply": "2023-03-04T17:49:07.612570Z"
    },
    "papermill": {
     "duration": 0.799227,
     "end_time": "2023-03-04T17:49:07.616063",
     "exception": false,
     "start_time": "2023-03-04T17:49:06.816836",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee32dabd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T17:49:07.624698Z",
     "iopub.status.busy": "2023-03-04T17:49:07.624080Z",
     "iopub.status.idle": "2023-03-04T17:49:08.129095Z",
     "shell.execute_reply": "2023-03-04T17:49:08.128014Z"
    },
    "papermill": {
     "duration": 0.512084,
     "end_time": "2023-03-04T17:49:08.131835",
     "exception": false,
     "start_time": "2023-03-04T17:49:07.619751",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.52</td>\n",
       "      <td>Premium</td>\n",
       "      <td>F</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.2</td>\n",
       "      <td>58.0</td>\n",
       "      <td>7.27</td>\n",
       "      <td>7.33</td>\n",
       "      <td>4.55</td>\n",
       "      <td>13619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.03</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>62.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>8.06</td>\n",
       "      <td>8.12</td>\n",
       "      <td>5.05</td>\n",
       "      <td>13387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.70</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>G</td>\n",
       "      <td>VS1</td>\n",
       "      <td>61.2</td>\n",
       "      <td>57.0</td>\n",
       "      <td>5.69</td>\n",
       "      <td>5.73</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.32</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>G</td>\n",
       "      <td>VS1</td>\n",
       "      <td>61.6</td>\n",
       "      <td>56.0</td>\n",
       "      <td>4.38</td>\n",
       "      <td>4.41</td>\n",
       "      <td>2.71</td>\n",
       "      <td>666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.70</td>\n",
       "      <td>Premium</td>\n",
       "      <td>G</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.6</td>\n",
       "      <td>59.0</td>\n",
       "      <td>7.65</td>\n",
       "      <td>7.61</td>\n",
       "      <td>4.77</td>\n",
       "      <td>14453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193568</th>\n",
       "      <td>0.31</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>D</td>\n",
       "      <td>VVS2</td>\n",
       "      <td>61.1</td>\n",
       "      <td>56.0</td>\n",
       "      <td>4.35</td>\n",
       "      <td>4.39</td>\n",
       "      <td>2.67</td>\n",
       "      <td>1130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193569</th>\n",
       "      <td>0.70</td>\n",
       "      <td>Premium</td>\n",
       "      <td>G</td>\n",
       "      <td>VVS2</td>\n",
       "      <td>60.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.77</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193570</th>\n",
       "      <td>0.73</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>F</td>\n",
       "      <td>SI1</td>\n",
       "      <td>63.1</td>\n",
       "      <td>57.0</td>\n",
       "      <td>5.72</td>\n",
       "      <td>5.75</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193571</th>\n",
       "      <td>0.34</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>D</td>\n",
       "      <td>SI1</td>\n",
       "      <td>62.9</td>\n",
       "      <td>55.0</td>\n",
       "      <td>4.45</td>\n",
       "      <td>4.49</td>\n",
       "      <td>2.81</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193572</th>\n",
       "      <td>0.71</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>60.8</td>\n",
       "      <td>64.0</td>\n",
       "      <td>5.73</td>\n",
       "      <td>5.71</td>\n",
       "      <td>3.48</td>\n",
       "      <td>2258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>193573 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        carat        cut color clarity  depth  table     x     y     z  price\n",
       "0        1.52    Premium     F     VS2   62.2   58.0  7.27  7.33  4.55  13619\n",
       "1        2.03  Very Good     J     SI2   62.0   58.0  8.06  8.12  5.05  13387\n",
       "2        0.70      Ideal     G     VS1   61.2   57.0  5.69  5.73  3.50   2772\n",
       "3        0.32      Ideal     G     VS1   61.6   56.0  4.38  4.41  2.71    666\n",
       "4        1.70    Premium     G     VS2   62.6   59.0  7.65  7.61  4.77  14453\n",
       "...       ...        ...   ...     ...    ...    ...   ...   ...   ...    ...\n",
       "193568   0.31      Ideal     D    VVS2   61.1   56.0  4.35  4.39  2.67   1130\n",
       "193569   0.70    Premium     G    VVS2   60.3   58.0  5.75  5.77  3.47   2874\n",
       "193570   0.73  Very Good     F     SI1   63.1   57.0  5.72  5.75  3.62   3036\n",
       "193571   0.34  Very Good     D     SI1   62.9   55.0  4.45  4.49  2.81    681\n",
       "193572   0.71       Good     E     SI2   60.8   64.0  5.73  5.71  3.48   2258\n",
       "\n",
       "[193573 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = Path('/kaggle/input/playground-series-s3e8/')\n",
    "train = pd.read_csv(data_path/'train.csv')\n",
    "del train['id']\n",
    "\n",
    "test = pd.read_csv(data_path/'test.csv')\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "119d8ebe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T17:49:08.141588Z",
     "iopub.status.busy": "2023-03-04T17:49:08.140594Z",
     "iopub.status.idle": "2023-03-04T17:49:08.159917Z",
     "shell.execute_reply": "2023-03-04T17:49:08.158810Z"
    },
    "papermill": {
     "duration": 0.026426,
     "end_time": "2023-03-04T17:49:08.162210",
     "exception": false,
     "start_time": "2023-03-04T17:49:08.135784",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['VS2', 'SI2', 'VS1', 'SI1', 'IF', 'VVS2', 'VVS1', 'I1'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['clarity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b030b6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T17:49:08.171361Z",
     "iopub.status.busy": "2023-03-04T17:49:08.170483Z",
     "iopub.status.idle": "2023-03-04T17:49:08.598839Z",
     "shell.execute_reply": "2023-03-04T17:49:08.597730Z"
    },
    "papermill": {
     "duration": 0.435517,
     "end_time": "2023-03-04T17:49:08.601414",
     "exception": false,
     "start_time": "2023-03-04T17:49:08.165897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the categorical predictors in the dataset have order\n",
    "# use the order information from the original dataset\n",
    "ordinal_encoding = {\n",
    "    'cut':{'Fair':0,'Good':1,'Very Good':2,'Premium':3,'Ideal':4}, # worst to best\n",
    "    'clarity':{c:i for i,c in enumerate(['IF','VVS1','VVS2','VS1','VS2','SI1','SI2','I1'])}, # best to worst\n",
    "    'color':{c:i for i,c in enumerate(['D','E','F','G','H','I','J'])} # best to worst\n",
    "}\n",
    "\n",
    "for col,mapper in ordinal_encoding.items():\n",
    "    train[col] = train[col].replace(mapper).astype(float)\n",
    "    test[col] = test[col].replace(mapper).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a6fe8e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T17:49:08.611956Z",
     "iopub.status.busy": "2023-03-04T17:49:08.610334Z",
     "iopub.status.idle": "2023-03-04T17:49:08.630400Z",
     "shell.execute_reply": "2023-03-04T17:49:08.629149Z"
    },
    "papermill": {
     "duration": 0.027153,
     "end_time": "2023-03-04T17:49:08.632533",
     "exception": false,
     "start_time": "2023-03-04T17:49:08.605380",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 193573 entries, 0 to 193572\n",
      "Data columns (total 10 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   carat    193573 non-null  float64\n",
      " 1   cut      193573 non-null  float64\n",
      " 2   color    193573 non-null  float64\n",
      " 3   clarity  193573 non-null  float64\n",
      " 4   depth    193573 non-null  float64\n",
      " 5   table    193573 non-null  float64\n",
      " 6   x        193573 non-null  float64\n",
      " 7   y        193573 non-null  float64\n",
      " 8   z        193573 non-null  float64\n",
      " 9   price    193573 non-null  int64  \n",
      "dtypes: float64(9), int64(1)\n",
      "memory usage: 14.8 MB\n"
     ]
    }
   ],
   "source": [
    "# SANITY check\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbbea5aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T17:49:08.642157Z",
     "iopub.status.busy": "2023-03-04T17:49:08.641880Z",
     "iopub.status.idle": "2023-03-04T17:49:08.808274Z",
     "shell.execute_reply": "2023-03-04T17:49:08.807075Z"
    },
    "papermill": {
     "duration": 0.1743,
     "end_time": "2023-03-04T17:49:08.811056",
     "exception": false,
     "start_time": "2023-03-04T17:49:08.636756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# preprocess data\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "\n",
    "input_sc = RobustScaler()\n",
    "output_sc = StandardScaler()\n",
    "\n",
    "X = input_sc.fit_transform(train.drop('price',axis=1).values)\n",
    "y = output_sc.fit_transform(train[['price']].values).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97ee078d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T17:49:08.820962Z",
     "iopub.status.busy": "2023-03-04T17:49:08.820450Z",
     "iopub.status.idle": "2023-03-04T17:49:14.292670Z",
     "shell.execute_reply": "2023-03-04T17:49:14.291577Z"
    },
    "papermill": {
     "duration": 5.480051,
     "end_time": "2023-03-04T17:49:14.295314",
     "exception": false,
     "start_time": "2023-03-04T17:49:08.815263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from typing import Dict\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73c2f34d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T17:49:14.305259Z",
     "iopub.status.busy": "2023-03-04T17:49:14.304624Z",
     "iopub.status.idle": "2023-03-04T17:49:14.320800Z",
     "shell.execute_reply": "2023-03-04T17:49:14.319909Z"
    },
    "papermill": {
     "duration": 0.023446,
     "end_time": "2023-03-04T17:49:14.322931",
     "exception": false,
     "start_time": "2023-03-04T17:49:14.299485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def construct_model(params:Dict) -> keras.Model:\n",
    "    \"\"\"\n",
    "    Build a 4-layer MLP for hyperparameter tuning\n",
    "    \"\"\"\n",
    "    n_hidden = 4 # TODO: use this as a hyperparameter\n",
    "    n_hidden_list = [params['hsize%d'%i] for i in range(1,n_hidden+1)]\n",
    "    dropouts_list = [params['dropout%d'%i] for i in range(1,n_hidden+1)]\n",
    "\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(n_hidden_list[0],input_shape=(X.shape[-1],)))\n",
    "    model.add(keras.layers.LayerNormalization())\n",
    "    model.add(keras.layers.Activation(keras.activations.relu))\n",
    "    model.add(keras.layers.Dropout(dropouts_list[0]))\n",
    "\n",
    "    if n_hidden > 1:\n",
    "        for i in range(1,n_hidden):\n",
    "            model.add(keras.layers.Dense(n_hidden_list[i]))\n",
    "            model.add(keras.layers.LayerNormalization())\n",
    "            model.add(keras.layers.Activation(keras.activations.relu))\n",
    "            model.add(keras.layers.Dropout(dropouts_list[i]))\n",
    "            \n",
    "    # output is between 0 and 1\n",
    "    model.add(keras.layers.Dense(1))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=params['learning_rate']),\n",
    "        loss='mean_squared_error'\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_and_fit(params:Dict,verbose:bool=False,resample_seed:int=0) -> keras.Model:\n",
    "    '''\n",
    "    Train a MLP with the given hyperparameters on a bootstrap sample. The function uses\n",
    "    the out-of-bag samples as the validation set for early stopping.\n",
    "    '''\n",
    "    # first draw bootrstrap samples\n",
    "    idxs_train = resample(np.arange(X.shape[0]),replace=True,random_state=resample_seed)\n",
    "    # use original observations not sampled as test data\n",
    "    sampled = set(idxs_train)\n",
    "    idxs_val = np.array([idx for idx in np.arange(X.shape[0]) if idx not in sampled])\n",
    "    print(idxs_val.shape[0])\n",
    "    \n",
    "    # get training and validation data\n",
    "    X_train,X_val,y_train,y_val = X[idxs_train,:],X[idxs_val,:], y[idxs_train],y[idxs_val]        \n",
    "        \n",
    "    # create model\n",
    "    model = construct_model(params)\n",
    "    \n",
    "    # optimization setup \n",
    "    EPOCHS = 100\n",
    "    BATCH_SIZE = params['batch_size']\n",
    "        \n",
    "    early_stopping = keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        verbose=0,\n",
    "        patience=10,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    # train model\n",
    "    _ = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=[early_stopping],\n",
    "        validation_data=(X_val, y_val),\n",
    "        verbose=verbose,\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d2fbbb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T17:49:14.331724Z",
     "iopub.status.busy": "2023-03-04T17:49:14.331263Z",
     "iopub.status.idle": "2023-03-04T17:49:14.336491Z",
     "shell.execute_reply": "2023-03-04T17:49:14.335583Z"
    },
    "papermill": {
     "duration": 0.011965,
     "end_time": "2023-03-04T17:49:14.338587",
     "exception": false,
     "start_time": "2023-03-04T17:49:14.326622",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# best hyperparameters found through hyperopt\n",
    "best = {\n",
    "    'batch_size': 459,\n",
    "    'dropout1': 0.05017815582897199,\n",
    "    'dropout2': 0.21965806468947463,\n",
    "    'dropout3': 0.10533572184114517,\n",
    "    'dropout4': 0.051436413944709755,\n",
    "    'hsize1': 128,\n",
    "    'hsize2': 137,\n",
    "    'hsize3': 86,\n",
    "    'hsize4': 117,\n",
    "    'learning_rate': 0.0007263155962552988\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f595b30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T17:49:14.347186Z",
     "iopub.status.busy": "2023-03-04T17:49:14.346927Z",
     "iopub.status.idle": "2023-03-04T18:08:16.529319Z",
     "shell.execute_reply": "2023-03-04T18:08:16.528302Z"
    },
    "papermill": {
     "duration": 1142.189475,
     "end_time": "2023-03-04T18:08:16.531702",
     "exception": false,
     "start_time": "2023-03-04T17:49:14.342227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********* Model 1 *********\n",
      "71284\n",
      "Epoch 1/100\n",
      "422/422 [==============================] - 6s 6ms/step - loss: 0.1157 - val_loss: 0.0310\n",
      "Epoch 2/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0407 - val_loss: 0.0245\n",
      "Epoch 3/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0345 - val_loss: 0.0232\n",
      "Epoch 4/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0319 - val_loss: 0.0225\n",
      "Epoch 5/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0303 - val_loss: 0.0225\n",
      "Epoch 6/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0294 - val_loss: 0.0222\n",
      "Epoch 7/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0284 - val_loss: 0.0229\n",
      "Epoch 8/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0281 - val_loss: 0.0228\n",
      "Epoch 9/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0276 - val_loss: 0.0221\n",
      "Epoch 10/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0272 - val_loss: 0.0234\n",
      "Epoch 11/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0267 - val_loss: 0.0220\n",
      "Epoch 12/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0265 - val_loss: 0.0216\n",
      "Epoch 13/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0264 - val_loss: 0.0217\n",
      "Epoch 14/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0259 - val_loss: 0.0212\n",
      "Epoch 15/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0258 - val_loss: 0.0214\n",
      "Epoch 16/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0254 - val_loss: 0.0217\n",
      "Epoch 17/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0254 - val_loss: 0.0215\n",
      "Epoch 18/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0253 - val_loss: 0.0218\n",
      "Epoch 19/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0250 - val_loss: 0.0217\n",
      "Epoch 20/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0249 - val_loss: 0.0210\n",
      "Epoch 21/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0247 - val_loss: 0.0209\n",
      "Epoch 22/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0247 - val_loss: 0.0216\n",
      "Epoch 23/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0243 - val_loss: 0.0210\n",
      "Epoch 24/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0246 - val_loss: 0.0210\n",
      "Epoch 25/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0242 - val_loss: 0.0209\n",
      "Epoch 26/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0242 - val_loss: 0.0218\n",
      "Epoch 27/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0242 - val_loss: 0.0208\n",
      "Epoch 28/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0241 - val_loss: 0.0208\n",
      "Epoch 29/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0240 - val_loss: 0.0208\n",
      "Epoch 30/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0240 - val_loss: 0.0209\n",
      "Epoch 31/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0238 - val_loss: 0.0207\n",
      "Epoch 32/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0237 - val_loss: 0.0207\n",
      "Epoch 33/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0236 - val_loss: 0.0210\n",
      "Epoch 34/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0237 - val_loss: 0.0219\n",
      "Epoch 35/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0236 - val_loss: 0.0210\n",
      "Epoch 36/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0236 - val_loss: 0.0211\n",
      "Epoch 37/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0234 - val_loss: 0.0215\n",
      "Epoch 38/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0233 - val_loss: 0.0213\n",
      "Epoch 39/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0235 - val_loss: 0.0209\n",
      "Epoch 40/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0234 - val_loss: 0.0206\n",
      "Epoch 41/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0232 - val_loss: 0.0211\n",
      "Epoch 42/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0233 - val_loss: 0.0206\n",
      "Epoch 43/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0231 - val_loss: 0.0207\n",
      "Epoch 44/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0232 - val_loss: 0.0207\n",
      "Epoch 45/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0232 - val_loss: 0.0207\n",
      "Epoch 46/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0231 - val_loss: 0.0208\n",
      "Epoch 47/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0231 - val_loss: 0.0205\n",
      "Epoch 48/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0230 - val_loss: 0.0205\n",
      "Epoch 49/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0229 - val_loss: 0.0207\n",
      "Epoch 50/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0229 - val_loss: 0.0211\n",
      "Epoch 51/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0231 - val_loss: 0.0205\n",
      "Epoch 52/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0229 - val_loss: 0.0209\n",
      "Epoch 53/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0228 - val_loss: 0.0206\n",
      "Epoch 54/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0228 - val_loss: 0.0204\n",
      "Epoch 55/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0229 - val_loss: 0.0206\n",
      "Epoch 56/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0228 - val_loss: 0.0205\n",
      "Epoch 57/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0228 - val_loss: 0.0208\n",
      "Epoch 58/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0227 - val_loss: 0.0206\n",
      "Epoch 59/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0227 - val_loss: 0.0209\n",
      "Epoch 60/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0227 - val_loss: 0.0207\n",
      "Epoch 61/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0227 - val_loss: 0.0207\n",
      "Epoch 62/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0227 - val_loss: 0.0212\n",
      "Epoch 63/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0228 - val_loss: 0.0207\n",
      "Epoch 64/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0225 - val_loss: 0.0208\n",
      "\n",
      "********* Model 2 *********\n",
      "71294\n",
      "Epoch 1/100\n",
      "422/422 [==============================] - 3s 6ms/step - loss: 0.1459 - val_loss: 0.0347\n",
      "Epoch 2/100\n",
      "422/422 [==============================] - 3s 6ms/step - loss: 0.0465 - val_loss: 0.0244\n",
      "Epoch 3/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0369 - val_loss: 0.0231\n",
      "Epoch 4/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0334 - val_loss: 0.0220\n",
      "Epoch 5/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0317 - val_loss: 0.0224\n",
      "Epoch 6/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0304 - val_loss: 0.0221\n",
      "Epoch 7/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0295 - val_loss: 0.0214\n",
      "Epoch 8/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0287 - val_loss: 0.0215\n",
      "Epoch 9/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0280 - val_loss: 0.0213\n",
      "Epoch 10/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0278 - val_loss: 0.0210\n",
      "Epoch 11/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0274 - val_loss: 0.0217\n",
      "Epoch 12/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0272 - val_loss: 0.0215\n",
      "Epoch 13/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0267 - val_loss: 0.0210\n",
      "Epoch 14/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0265 - val_loss: 0.0214\n",
      "Epoch 15/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0263 - val_loss: 0.0221\n",
      "Epoch 16/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0261 - val_loss: 0.0208\n",
      "Epoch 17/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0257 - val_loss: 0.0206\n",
      "Epoch 18/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0258 - val_loss: 0.0205\n",
      "Epoch 19/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0257 - val_loss: 0.0205\n",
      "Epoch 20/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0255 - val_loss: 0.0205\n",
      "Epoch 21/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0253 - val_loss: 0.0213\n",
      "Epoch 22/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0252 - val_loss: 0.0225\n",
      "Epoch 23/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0249 - val_loss: 0.0214\n",
      "Epoch 24/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0248 - val_loss: 0.0207\n",
      "Epoch 25/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0248 - val_loss: 0.0201\n",
      "Epoch 26/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0245 - val_loss: 0.0224\n",
      "Epoch 27/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0245 - val_loss: 0.0200\n",
      "Epoch 28/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0243 - val_loss: 0.0200\n",
      "Epoch 29/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0245 - val_loss: 0.0204\n",
      "Epoch 30/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0242 - val_loss: 0.0205\n",
      "Epoch 31/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0241 - val_loss: 0.0203\n",
      "Epoch 32/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0240 - val_loss: 0.0202\n",
      "Epoch 33/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0241 - val_loss: 0.0199\n",
      "Epoch 34/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0236 - val_loss: 0.0199\n",
      "Epoch 35/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0238 - val_loss: 0.0200\n",
      "Epoch 36/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0237 - val_loss: 0.0205\n",
      "Epoch 37/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0239 - val_loss: 0.0203\n",
      "Epoch 38/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0237 - val_loss: 0.0201\n",
      "Epoch 39/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0235 - val_loss: 0.0201\n",
      "Epoch 40/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0236 - val_loss: 0.0201\n",
      "Epoch 41/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0236 - val_loss: 0.0200\n",
      "Epoch 42/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0235 - val_loss: 0.0204\n",
      "Epoch 43/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0233 - val_loss: 0.0201\n",
      "Epoch 44/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0233 - val_loss: 0.0199\n",
      "\n",
      "********* Model 3 *********\n",
      "71147\n",
      "Epoch 1/100\n",
      "422/422 [==============================] - 3s 6ms/step - loss: 0.1245 - val_loss: 0.0294\n",
      "Epoch 2/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0430 - val_loss: 0.0283\n",
      "Epoch 3/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0358 - val_loss: 0.0239\n",
      "Epoch 4/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0324 - val_loss: 0.0235\n",
      "Epoch 5/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0306 - val_loss: 0.0238\n",
      "Epoch 6/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0295 - val_loss: 0.0228\n",
      "Epoch 7/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0285 - val_loss: 0.0237\n",
      "Epoch 8/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0280 - val_loss: 0.0233\n",
      "Epoch 9/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0274 - val_loss: 0.0226\n",
      "Epoch 10/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0270 - val_loss: 0.0221\n",
      "Epoch 11/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0269 - val_loss: 0.0230\n",
      "Epoch 12/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0262 - val_loss: 0.0223\n",
      "Epoch 13/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0261 - val_loss: 0.0224\n",
      "Epoch 14/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0256 - val_loss: 0.0224\n",
      "Epoch 15/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0254 - val_loss: 0.0220\n",
      "Epoch 16/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0253 - val_loss: 0.0225\n",
      "Epoch 17/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0250 - val_loss: 0.0218\n",
      "Epoch 18/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0248 - val_loss: 0.0224\n",
      "Epoch 19/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0248 - val_loss: 0.0220\n",
      "Epoch 20/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0246 - val_loss: 0.0216\n",
      "Epoch 21/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0244 - val_loss: 0.0217\n",
      "Epoch 22/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0242 - val_loss: 0.0216\n",
      "Epoch 23/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0243 - val_loss: 0.0216\n",
      "Epoch 24/100\n",
      "422/422 [==============================] - 3s 6ms/step - loss: 0.0240 - val_loss: 0.0215\n",
      "Epoch 25/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0239 - val_loss: 0.0214\n",
      "Epoch 26/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0239 - val_loss: 0.0217\n",
      "Epoch 27/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0237 - val_loss: 0.0213\n",
      "Epoch 28/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0237 - val_loss: 0.0244\n",
      "Epoch 29/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0237 - val_loss: 0.0211\n",
      "Epoch 30/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0235 - val_loss: 0.0212\n",
      "Epoch 31/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0235 - val_loss: 0.0213\n",
      "Epoch 32/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0233 - val_loss: 0.0210\n",
      "Epoch 33/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0231 - val_loss: 0.0212\n",
      "Epoch 34/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0231 - val_loss: 0.0210\n",
      "Epoch 35/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0231 - val_loss: 0.0218\n",
      "Epoch 36/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0232 - val_loss: 0.0218\n",
      "Epoch 37/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0229 - val_loss: 0.0210\n",
      "Epoch 38/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0229 - val_loss: 0.0209\n",
      "Epoch 39/100\n",
      "422/422 [==============================] - 3s 6ms/step - loss: 0.0230 - val_loss: 0.0210\n",
      "Epoch 40/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0229 - val_loss: 0.0209\n",
      "Epoch 41/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0227 - val_loss: 0.0214\n",
      "Epoch 42/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0229 - val_loss: 0.0211\n",
      "Epoch 43/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0226 - val_loss: 0.0210\n",
      "Epoch 44/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0227 - val_loss: 0.0210\n",
      "Epoch 45/100\n",
      "422/422 [==============================] - 3s 6ms/step - loss: 0.0226 - val_loss: 0.0217\n",
      "Epoch 46/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0226 - val_loss: 0.0211\n",
      "Epoch 47/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0226 - val_loss: 0.0211\n",
      "Epoch 48/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0225 - val_loss: 0.0215\n",
      "\n",
      "********* Model 4 *********\n",
      "71299\n",
      "Epoch 1/100\n",
      "422/422 [==============================] - 4s 6ms/step - loss: 0.1267 - val_loss: 0.0301\n",
      "Epoch 2/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0439 - val_loss: 0.0260\n",
      "Epoch 3/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0364 - val_loss: 0.0235\n",
      "Epoch 4/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0328 - val_loss: 0.0234\n",
      "Epoch 5/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0311 - val_loss: 0.0247\n",
      "Epoch 6/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0297 - val_loss: 0.0228\n",
      "Epoch 7/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0289 - val_loss: 0.0237\n",
      "Epoch 8/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0282 - val_loss: 0.0220\n",
      "Epoch 9/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0278 - val_loss: 0.0227\n",
      "Epoch 10/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0270 - val_loss: 0.0224\n",
      "Epoch 11/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0266 - val_loss: 0.0218\n",
      "Epoch 12/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0267 - val_loss: 0.0218\n",
      "Epoch 13/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0262 - val_loss: 0.0219\n",
      "Epoch 14/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0260 - val_loss: 0.0216\n",
      "Epoch 15/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0256 - val_loss: 0.0218\n",
      "Epoch 16/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0255 - val_loss: 0.0216\n",
      "Epoch 17/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0253 - val_loss: 0.0222\n",
      "Epoch 18/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0252 - val_loss: 0.0220\n",
      "Epoch 19/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0249 - val_loss: 0.0214\n",
      "Epoch 20/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0248 - val_loss: 0.0216\n",
      "Epoch 21/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0246 - val_loss: 0.0221\n",
      "Epoch 22/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0247 - val_loss: 0.0222\n",
      "Epoch 23/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0243 - val_loss: 0.0216\n",
      "Epoch 24/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0243 - val_loss: 0.0214\n",
      "Epoch 25/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0243 - val_loss: 0.0213\n",
      "Epoch 26/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0241 - val_loss: 0.0214\n",
      "Epoch 27/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0242 - val_loss: 0.0213\n",
      "Epoch 28/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0240 - val_loss: 0.0209\n",
      "Epoch 29/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0238 - val_loss: 0.0231\n",
      "Epoch 30/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0239 - val_loss: 0.0219\n",
      "Epoch 31/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0238 - val_loss: 0.0214\n",
      "Epoch 32/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0238 - val_loss: 0.0221\n",
      "Epoch 33/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0235 - val_loss: 0.0220\n",
      "Epoch 34/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0235 - val_loss: 0.0212\n",
      "Epoch 35/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0232 - val_loss: 0.0211\n",
      "Epoch 36/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0234 - val_loss: 0.0217\n",
      "Epoch 37/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0235 - val_loss: 0.0207\n",
      "Epoch 38/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0234 - val_loss: 0.0212\n",
      "Epoch 39/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0232 - val_loss: 0.0214\n",
      "Epoch 40/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0232 - val_loss: 0.0212\n",
      "Epoch 41/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0232 - val_loss: 0.0208\n",
      "Epoch 42/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0231 - val_loss: 0.0210\n",
      "Epoch 43/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0231 - val_loss: 0.0208\n",
      "Epoch 44/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0230 - val_loss: 0.0208\n",
      "Epoch 45/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0231 - val_loss: 0.0215\n",
      "Epoch 46/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0229 - val_loss: 0.0210\n",
      "Epoch 47/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0230 - val_loss: 0.0211\n",
      "\n",
      "********* Model 5 *********\n",
      "71460\n",
      "Epoch 1/100\n",
      "422/422 [==============================] - 3s 6ms/step - loss: 0.1692 - val_loss: 0.0320\n",
      "Epoch 2/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0481 - val_loss: 0.0293\n",
      "Epoch 3/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0385 - val_loss: 0.0260\n",
      "Epoch 4/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0347 - val_loss: 0.0238\n",
      "Epoch 5/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0323 - val_loss: 0.0250\n",
      "Epoch 6/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0308 - val_loss: 0.0237\n",
      "Epoch 7/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0299 - val_loss: 0.0236\n",
      "Epoch 8/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0289 - val_loss: 0.0230\n",
      "Epoch 9/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0283 - val_loss: 0.0232\n",
      "Epoch 10/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0279 - val_loss: 0.0233\n",
      "Epoch 11/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0273 - val_loss: 0.0233\n",
      "Epoch 12/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0268 - val_loss: 0.0234\n",
      "Epoch 13/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0264 - val_loss: 0.0233\n",
      "Epoch 14/100\n",
      "422/422 [==============================] - 3s 6ms/step - loss: 0.0260 - val_loss: 0.0223\n",
      "Epoch 15/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0259 - val_loss: 0.0220\n",
      "Epoch 16/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0256 - val_loss: 0.0223\n",
      "Epoch 17/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0256 - val_loss: 0.0221\n",
      "Epoch 18/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0253 - val_loss: 0.0218\n",
      "Epoch 19/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0251 - val_loss: 0.0219\n",
      "Epoch 20/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0245 - val_loss: 0.0216\n",
      "Epoch 21/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0246 - val_loss: 0.0218\n",
      "Epoch 22/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0245 - val_loss: 0.0215\n",
      "Epoch 23/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0243 - val_loss: 0.0216\n",
      "Epoch 24/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0240 - val_loss: 0.0217\n",
      "Epoch 25/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0242 - val_loss: 0.0229\n",
      "Epoch 26/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0240 - val_loss: 0.0213\n",
      "Epoch 27/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0238 - val_loss: 0.0214\n",
      "Epoch 28/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0237 - val_loss: 0.0211\n",
      "Epoch 29/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0237 - val_loss: 0.0212\n",
      "Epoch 30/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0236 - val_loss: 0.0218\n",
      "Epoch 31/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0234 - val_loss: 0.0220\n",
      "Epoch 32/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0236 - val_loss: 0.0210\n",
      "Epoch 33/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0232 - val_loss: 0.0213\n",
      "Epoch 34/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0233 - val_loss: 0.0212\n",
      "Epoch 35/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0232 - val_loss: 0.0217\n",
      "Epoch 36/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0231 - val_loss: 0.0211\n",
      "Epoch 37/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0232 - val_loss: 0.0210\n",
      "Epoch 38/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0230 - val_loss: 0.0215\n",
      "Epoch 39/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0230 - val_loss: 0.0213\n",
      "Epoch 40/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0230 - val_loss: 0.0215\n",
      "Epoch 41/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0229 - val_loss: 0.0213\n",
      "Epoch 42/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0228 - val_loss: 0.0214\n",
      "Epoch 43/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0228 - val_loss: 0.0212\n",
      "Epoch 44/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0228 - val_loss: 0.0213\n",
      "Epoch 45/100\n",
      "422/422 [==============================] - 3s 7ms/step - loss: 0.0227 - val_loss: 0.0210\n",
      "Epoch 46/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0229 - val_loss: 0.0212\n",
      "Epoch 47/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0226 - val_loss: 0.0210\n",
      "\n",
      "********* Model 6 *********\n",
      "71038\n",
      "Epoch 1/100\n",
      "422/422 [==============================] - 3s 6ms/step - loss: 0.1056 - val_loss: 0.0265\n",
      "Epoch 2/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0410 - val_loss: 0.0240\n",
      "Epoch 3/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0347 - val_loss: 0.0228\n",
      "Epoch 4/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0320 - val_loss: 0.0222\n",
      "Epoch 5/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0303 - val_loss: 0.0223\n",
      "Epoch 6/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0293 - val_loss: 0.0222\n",
      "Epoch 7/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0285 - val_loss: 0.0215\n",
      "Epoch 8/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0275 - val_loss: 0.0214\n",
      "Epoch 9/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0273 - val_loss: 0.0215\n",
      "Epoch 10/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0268 - val_loss: 0.0210\n",
      "Epoch 11/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0266 - val_loss: 0.0215\n",
      "Epoch 12/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0264 - val_loss: 0.0228\n",
      "Epoch 13/100\n",
      "422/422 [==============================] - 3s 6ms/step - loss: 0.0262 - val_loss: 0.0216\n",
      "Epoch 14/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0259 - val_loss: 0.0211\n",
      "Epoch 15/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0258 - val_loss: 0.0217\n",
      "Epoch 16/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0257 - val_loss: 0.0207\n",
      "Epoch 17/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0254 - val_loss: 0.0219\n",
      "Epoch 18/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0253 - val_loss: 0.0206\n",
      "Epoch 19/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0252 - val_loss: 0.0211\n",
      "Epoch 20/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0250 - val_loss: 0.0203\n",
      "Epoch 21/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0247 - val_loss: 0.0205\n",
      "Epoch 22/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0248 - val_loss: 0.0211\n",
      "Epoch 23/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0245 - val_loss: 0.0205\n",
      "Epoch 24/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0245 - val_loss: 0.0204\n",
      "Epoch 25/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0243 - val_loss: 0.0200\n",
      "Epoch 26/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0243 - val_loss: 0.0200\n",
      "Epoch 27/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0243 - val_loss: 0.0202\n",
      "Epoch 28/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0242 - val_loss: 0.0201\n",
      "Epoch 29/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0239 - val_loss: 0.0203\n",
      "Epoch 30/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0240 - val_loss: 0.0204\n",
      "Epoch 31/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0238 - val_loss: 0.0199\n",
      "Epoch 32/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0240 - val_loss: 0.0202\n",
      "Epoch 33/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0238 - val_loss: 0.0199\n",
      "Epoch 34/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0238 - val_loss: 0.0200\n",
      "Epoch 35/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0237 - val_loss: 0.0201\n",
      "Epoch 36/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0237 - val_loss: 0.0204\n",
      "Epoch 37/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0237 - val_loss: 0.0204\n",
      "Epoch 38/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0235 - val_loss: 0.0203\n",
      "Epoch 39/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0235 - val_loss: 0.0199\n",
      "Epoch 40/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0235 - val_loss: 0.0202\n",
      "Epoch 41/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0236 - val_loss: 0.0204\n",
      "\n",
      "********* Model 7 *********\n",
      "71362\n",
      "Epoch 1/100\n",
      "422/422 [==============================] - 3s 5ms/step - loss: 0.1753 - val_loss: 0.0306\n",
      "Epoch 2/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0488 - val_loss: 0.0258\n",
      "Epoch 3/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0388 - val_loss: 0.0248\n",
      "Epoch 4/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0347 - val_loss: 0.0256\n",
      "Epoch 5/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0326 - val_loss: 0.0232\n",
      "Epoch 6/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0313 - val_loss: 0.0230\n",
      "Epoch 7/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0302 - val_loss: 0.0229\n",
      "Epoch 8/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0293 - val_loss: 0.0230\n",
      "Epoch 9/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0286 - val_loss: 0.0224\n",
      "Epoch 10/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0279 - val_loss: 0.0232\n",
      "Epoch 11/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0276 - val_loss: 0.0230\n",
      "Epoch 12/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0270 - val_loss: 0.0222\n",
      "Epoch 13/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0267 - val_loss: 0.0221\n",
      "Epoch 14/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0264 - val_loss: 0.0218\n",
      "Epoch 15/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0264 - val_loss: 0.0221\n",
      "Epoch 16/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0260 - val_loss: 0.0229\n",
      "Epoch 17/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0259 - val_loss: 0.0222\n",
      "Epoch 18/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0256 - val_loss: 0.0213\n",
      "Epoch 19/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0255 - val_loss: 0.0222\n",
      "Epoch 20/100\n",
      "422/422 [==============================] - 3s 6ms/step - loss: 0.0253 - val_loss: 0.0213\n",
      "Epoch 21/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0252 - val_loss: 0.0212\n",
      "Epoch 22/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0251 - val_loss: 0.0215\n",
      "Epoch 23/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0248 - val_loss: 0.0214\n",
      "Epoch 24/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0248 - val_loss: 0.0211\n",
      "Epoch 25/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0247 - val_loss: 0.0218\n",
      "Epoch 26/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0246 - val_loss: 0.0217\n",
      "Epoch 27/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0245 - val_loss: 0.0215\n",
      "Epoch 28/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0244 - val_loss: 0.0210\n",
      "Epoch 29/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0242 - val_loss: 0.0209\n",
      "Epoch 30/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0242 - val_loss: 0.0218\n",
      "Epoch 31/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0241 - val_loss: 0.0210\n",
      "Epoch 32/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0238 - val_loss: 0.0210\n",
      "Epoch 33/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0238 - val_loss: 0.0208\n",
      "Epoch 34/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0240 - val_loss: 0.0209\n",
      "Epoch 35/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0237 - val_loss: 0.0212\n",
      "Epoch 36/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0237 - val_loss: 0.0217\n",
      "Epoch 37/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0237 - val_loss: 0.0212\n",
      "Epoch 38/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0235 - val_loss: 0.0209\n",
      "Epoch 39/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0238 - val_loss: 0.0208\n",
      "Epoch 40/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0234 - val_loss: 0.0212\n",
      "Epoch 41/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0235 - val_loss: 0.0209\n",
      "Epoch 42/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0234 - val_loss: 0.0214\n",
      "Epoch 43/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0234 - val_loss: 0.0214\n",
      "\n",
      "********* Model 8 *********\n",
      "70997\n",
      "Epoch 1/100\n",
      "422/422 [==============================] - 4s 5ms/step - loss: 0.1213 - val_loss: 0.0273\n",
      "Epoch 2/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0423 - val_loss: 0.0259\n",
      "Epoch 3/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0354 - val_loss: 0.0236\n",
      "Epoch 4/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0322 - val_loss: 0.0236\n",
      "Epoch 5/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0305 - val_loss: 0.0237\n",
      "Epoch 6/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0295 - val_loss: 0.0227\n",
      "Epoch 7/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0285 - val_loss: 0.0239\n",
      "Epoch 8/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0276 - val_loss: 0.0229\n",
      "Epoch 9/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0273 - val_loss: 0.0230\n",
      "Epoch 10/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0268 - val_loss: 0.0223\n",
      "Epoch 11/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0265 - val_loss: 0.0222\n",
      "Epoch 12/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0260 - val_loss: 0.0220\n",
      "Epoch 13/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0257 - val_loss: 0.0226\n",
      "Epoch 14/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0257 - val_loss: 0.0216\n",
      "Epoch 15/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0255 - val_loss: 0.0218\n",
      "Epoch 16/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0250 - val_loss: 0.0230\n",
      "Epoch 17/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0249 - val_loss: 0.0220\n",
      "Epoch 18/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0248 - val_loss: 0.0213\n",
      "Epoch 19/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0246 - val_loss: 0.0217\n",
      "Epoch 20/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0245 - val_loss: 0.0219\n",
      "Epoch 21/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0244 - val_loss: 0.0219\n",
      "Epoch 22/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0243 - val_loss: 0.0224\n",
      "Epoch 23/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0243 - val_loss: 0.0229\n",
      "Epoch 24/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0241 - val_loss: 0.0213\n",
      "Epoch 25/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0240 - val_loss: 0.0217\n",
      "Epoch 26/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0240 - val_loss: 0.0217\n",
      "Epoch 27/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0237 - val_loss: 0.0213\n",
      "Epoch 28/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0237 - val_loss: 0.0220\n",
      "Epoch 29/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0235 - val_loss: 0.0213\n",
      "Epoch 30/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0235 - val_loss: 0.0212\n",
      "Epoch 31/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0234 - val_loss: 0.0209\n",
      "Epoch 32/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0234 - val_loss: 0.0209\n",
      "Epoch 33/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0234 - val_loss: 0.0215\n",
      "Epoch 34/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0234 - val_loss: 0.0220\n",
      "Epoch 35/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0232 - val_loss: 0.0210\n",
      "Epoch 36/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0231 - val_loss: 0.0209\n",
      "Epoch 37/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0232 - val_loss: 0.0212\n",
      "Epoch 38/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0230 - val_loss: 0.0212\n",
      "Epoch 39/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0230 - val_loss: 0.0218\n",
      "Epoch 40/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0230 - val_loss: 0.0217\n",
      "Epoch 41/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0229 - val_loss: 0.0214\n",
      "Epoch 42/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0228 - val_loss: 0.0210\n",
      "Epoch 43/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0228 - val_loss: 0.0210\n",
      "Epoch 44/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0228 - val_loss: 0.0210\n",
      "Epoch 45/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0228 - val_loss: 0.0210\n",
      "Epoch 46/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0228 - val_loss: 0.0212\n",
      "\n",
      "********* Model 9 *********\n",
      "71146\n",
      "Epoch 1/100\n",
      "422/422 [==============================] - 3s 5ms/step - loss: 0.1116 - val_loss: 0.0345\n",
      "Epoch 2/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0406 - val_loss: 0.0247\n",
      "Epoch 3/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0340 - val_loss: 0.0236\n",
      "Epoch 4/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0310 - val_loss: 0.0236\n",
      "Epoch 5/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0298 - val_loss: 0.0229\n",
      "Epoch 6/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0288 - val_loss: 0.0223\n",
      "Epoch 7/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0278 - val_loss: 0.0227\n",
      "Epoch 8/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0272 - val_loss: 0.0227\n",
      "Epoch 9/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0271 - val_loss: 0.0225\n",
      "Epoch 10/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0265 - val_loss: 0.0235\n",
      "Epoch 11/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0260 - val_loss: 0.0218\n",
      "Epoch 12/100\n",
      "422/422 [==============================] - 3s 6ms/step - loss: 0.0257 - val_loss: 0.0230\n",
      "Epoch 13/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0256 - val_loss: 0.0218\n",
      "Epoch 14/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0255 - val_loss: 0.0213\n",
      "Epoch 15/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0252 - val_loss: 0.0228\n",
      "Epoch 16/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0250 - val_loss: 0.0217\n",
      "Epoch 17/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0246 - val_loss: 0.0218\n",
      "Epoch 18/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0247 - val_loss: 0.0214\n",
      "Epoch 19/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0246 - val_loss: 0.0211\n",
      "Epoch 20/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0243 - val_loss: 0.0221\n",
      "Epoch 21/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0242 - val_loss: 0.0213\n",
      "Epoch 22/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0241 - val_loss: 0.0213\n",
      "Epoch 23/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0241 - val_loss: 0.0215\n",
      "Epoch 24/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0238 - val_loss: 0.0211\n",
      "Epoch 25/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0238 - val_loss: 0.0216\n",
      "Epoch 26/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0239 - val_loss: 0.0212\n",
      "Epoch 27/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0238 - val_loss: 0.0211\n",
      "Epoch 28/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0235 - val_loss: 0.0210\n",
      "Epoch 29/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0235 - val_loss: 0.0208\n",
      "Epoch 30/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0234 - val_loss: 0.0207\n",
      "Epoch 31/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0234 - val_loss: 0.0208\n",
      "Epoch 32/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0232 - val_loss: 0.0212\n",
      "Epoch 33/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0232 - val_loss: 0.0218\n",
      "Epoch 34/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0231 - val_loss: 0.0209\n",
      "Epoch 35/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0231 - val_loss: 0.0206\n",
      "Epoch 36/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0231 - val_loss: 0.0210\n",
      "Epoch 37/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0230 - val_loss: 0.0205\n",
      "Epoch 38/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0229 - val_loss: 0.0210\n",
      "Epoch 39/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0230 - val_loss: 0.0211\n",
      "Epoch 40/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0228 - val_loss: 0.0209\n",
      "Epoch 41/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0229 - val_loss: 0.0206\n",
      "Epoch 42/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0228 - val_loss: 0.0208\n",
      "Epoch 43/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0228 - val_loss: 0.0213\n",
      "Epoch 44/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0227 - val_loss: 0.0208\n",
      "Epoch 45/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0227 - val_loss: 0.0211\n",
      "Epoch 46/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0226 - val_loss: 0.0217\n",
      "Epoch 47/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0225 - val_loss: 0.0206\n",
      "\n",
      "********* Model 10 *********\n",
      "71321\n",
      "Epoch 1/100\n",
      "422/422 [==============================] - 4s 6ms/step - loss: 0.1163 - val_loss: 0.0301\n",
      "Epoch 2/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0429 - val_loss: 0.0244\n",
      "Epoch 3/100\n",
      "422/422 [==============================] - 3s 6ms/step - loss: 0.0357 - val_loss: 0.0246\n",
      "Epoch 4/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0325 - val_loss: 0.0236\n",
      "Epoch 5/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0305 - val_loss: 0.0229\n",
      "Epoch 6/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0295 - val_loss: 0.0228\n",
      "Epoch 7/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0287 - val_loss: 0.0227\n",
      "Epoch 8/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0282 - val_loss: 0.0224\n",
      "Epoch 9/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0273 - val_loss: 0.0232\n",
      "Epoch 10/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0272 - val_loss: 0.0233\n",
      "Epoch 11/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0266 - val_loss: 0.0226\n",
      "Epoch 12/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0262 - val_loss: 0.0223\n",
      "Epoch 13/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0259 - val_loss: 0.0218\n",
      "Epoch 14/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0257 - val_loss: 0.0219\n",
      "Epoch 15/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0256 - val_loss: 0.0216\n",
      "Epoch 16/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0253 - val_loss: 0.0216\n",
      "Epoch 17/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0249 - val_loss: 0.0219\n",
      "Epoch 18/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0249 - val_loss: 0.0220\n",
      "Epoch 19/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0246 - val_loss: 0.0216\n",
      "Epoch 20/100\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.0247 - val_loss: 0.0217\n",
      "Epoch 21/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0244 - val_loss: 0.0226\n",
      "Epoch 22/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0244 - val_loss: 0.0216\n",
      "Epoch 23/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0242 - val_loss: 0.0219\n",
      "Epoch 24/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0240 - val_loss: 0.0216\n",
      "Epoch 25/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0240 - val_loss: 0.0216\n",
      "\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "n_ensemble = 10\n",
    "models = [None]*n_ensemble\n",
    "\n",
    "for i in range(n_ensemble):\n",
    "    print(f'********* Model {i+1} *********')\n",
    "    models[i] = build_and_fit(best,verbose=True,resample_seed=i)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d56501b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T18:08:18.139559Z",
     "iopub.status.busy": "2023-03-04T18:08:18.139175Z",
     "iopub.status.idle": "2023-03-04T18:08:48.162773Z",
     "shell.execute_reply": "2023-03-04T18:08:48.161729Z"
    },
    "papermill": {
     "duration": 30.860064,
     "end_time": "2023-03-04T18:08:48.164952",
     "exception": false,
     "start_time": "2023-03-04T18:08:17.304888",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 9)]          0           []                               \n",
      "                                                                                                  \n",
      " sequential (Sequential)        (None, 1)            42054       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " sequential_1 (Sequential)      (None, 1)            42054       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " sequential_2 (Sequential)      (None, 1)            42054       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " sequential_3 (Sequential)      (None, 1)            42054       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " sequential_4 (Sequential)      (None, 1)            42054       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " sequential_5 (Sequential)      (None, 1)            42054       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " sequential_6 (Sequential)      (None, 1)            42054       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " sequential_7 (Sequential)      (None, 1)            42054       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " sequential_8 (Sequential)      (None, 1)            42054       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " sequential_9 (Sequential)      (None, 1)            42054       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " average (Average)              (None, 1)            0           ['sequential[0][0]',             \n",
      "                                                                  'sequential_1[0][0]',           \n",
      "                                                                  'sequential_2[0][0]',           \n",
      "                                                                  'sequential_3[0][0]',           \n",
      "                                                                  'sequential_4[0][0]',           \n",
      "                                                                  'sequential_5[0][0]',           \n",
      "                                                                  'sequential_6[0][0]',           \n",
      "                                                                  'sequential_7[0][0]',           \n",
      "                                                                  'sequential_8[0][0]',           \n",
      "                                                                  'sequential_9[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 420,540\n",
      "Trainable params: 420,540\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Create ensemble model\n",
    "model_input = keras.Input(shape=(X.shape[1],))\n",
    "model_outputs = [model(model_input) for model in models]\n",
    "ensemble_output = keras.layers.Average()(model_outputs)\n",
    "ensemble_model = keras.Model(inputs=model_input, outputs=ensemble_output)\n",
    "\n",
    "print(ensemble_model.summary())\n",
    "\n",
    "ensemble_model.save('ensemble_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "604270be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T18:08:49.769786Z",
     "iopub.status.busy": "2023-03-04T18:08:49.768890Z",
     "iopub.status.idle": "2023-03-04T18:09:15.354787Z",
     "shell.execute_reply": "2023-03-04T18:09:15.353734Z"
    },
    "papermill": {
     "duration": 26.363448,
     "end_time": "2023-03-04T18:09:15.357637",
     "exception": false,
     "start_time": "2023-03-04T18:08:48.994189",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4033/4033 [==============================] - 23s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "# generate predictions on the test set\n",
    "X_test = input_sc.transform(test.drop('id',axis=1).values)\n",
    "y_test_pred = ensemble_model.predict(X_test)\n",
    "\n",
    "y_test_pred_orig = output_sc.inverse_transform(y_test_pred.reshape(-1,1)).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fd74524",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T18:09:17.018477Z",
     "iopub.status.busy": "2023-03-04T18:09:17.018106Z",
     "iopub.status.idle": "2023-03-04T18:09:17.220357Z",
     "shell.execute_reply": "2023-03-04T18:09:17.219324Z"
    },
    "papermill": {
     "duration": 1.001428,
     "end_time": "2023-03-04T18:09:17.223164",
     "exception": false,
     "start_time": "2023-03-04T18:09:16.221736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id':test['id'],'price':y_test_pred_orig })\n",
    "submission.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000ac930",
   "metadata": {
    "papermill": {
     "duration": 0.801372,
     "end_time": "2023-03-04T18:09:18.876003",
     "exception": false,
     "start_time": "2023-03-04T18:09:18.074631",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1225.532586,
   "end_time": "2023-03-04T18:09:23.579521",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-04T17:48:58.046935",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
